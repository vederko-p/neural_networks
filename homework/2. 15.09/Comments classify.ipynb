{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В представленной задаче необходимо по тексту комментария определить степень его токсичности. Это задача классификации на $K$ классов, которые могут пересекаться:  \n",
    "<center>$\n",
    "\\begin{equation*}\n",
    "    Y\\in\\{0,1\\}^K\n",
    "\\end{equation*}$\n",
    "</center>\n",
    "\n",
    "возможные классы:\n",
    "- toxic;\n",
    "- severe_toxic;\n",
    "- obscene;\n",
    "- threat;\n",
    "- insult;\n",
    "- identity_hate.\n",
    "\n",
    "Загрузим имеющиеся данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/toxic_comment.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc['0001b41b1c6bb37e', 'comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве предварителного анализа рассмотрим распределение классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"variable\", hue=\"value\", data=pd.melt(data.drop('comment_text', axis=1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что классы несбалансированны. Это необходимо учитывать при оценке качетсва модели.\n",
    "\n",
    "Предварительно разобъем выборку на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['comment_text'], \n",
    "                                                    data.drop('comment_text', axis=1), \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что распределения в выборках совпадают:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"variable\", hue=\"value\", data=pd.melt(y_train))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"variable\", hue=\"value\", data=pd.melt(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Преобразование текстовых данных**\n",
    "Для преобразования текстов комментариев в числовые векторы воспользуемся методами `CountVectorizer` и `TfIdfVectorizer` из пакета `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с `TfidfVectorizer`. Чтобы составить корпус слов и посчитать число вхождений каждого слова в комментарии и его частоту встречаемости в других документах, необходимо последовательно применить функции `fit` и `transform` в `TfidfVectorizer`, или же сразу `fit_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = TfidfVectorizer(max_features=30000, sublinear_tf=True, \n",
    "                            strip_accents='unicode', analyzer='word', \n",
    "                            token_pattern=r'\\w{1,}')\n",
    "\n",
    "# max_features - какое кол-во наиболее частых слов запомнить\n",
    "# sublinear_tf - TF-IDF\n",
    "# strip_accents - кодировка\n",
    "# analyzer='word' - слова в качестве признаков\n",
    "# token_pattern - регулярное выражение для токенов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_train = count_vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106912x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4701344 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом `TfidfVectorizer` запоминает 30000 наиболее частых слов, которые встречались в комментариях из `X_train`. Всего в корпусе оказалось 149271 слово. Теперь необходимо посчитать количество вхождений каждого из слов корпуса для тестового набора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_test = count_vec.transform(X_test)\n",
    "# Здесь применяется только transofrm ввиду того, что результаты\n",
    "# на тестовых данных должны зависеть от обучения на тестовой выборке.\n",
    "# Обучение ни в коем случае не должно проходить обособленно на бвух выборках.\n",
    "# Что натренировали, то и проверяем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52659x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2307197 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Построение модели логистической регрессии**  \n",
    "Решение задачи классификации на пересекающихся $K$ классов может быть сведено к решению $K$ задач бинарной классификации. В задачах с большим количеством признаков хорошие результаты показывают линейные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<h3> Задание 1.</h3>\n",
    "<p></p>\n",
    "\n",
    " <ol>\n",
    "  <li>Решить поставленную задачу с помощью модели логистической регрессии. Для этого необходимо обучить 6 моделей на полученных векторах текстов comments_vec_train и каждом из столбцов y_train.</li>\n",
    " <p></p>\n",
    "\n",
    "      \n",
    "  <li>Для тестового набора данных comments_vec_test предсказать, принадлежит ли комментарий к каждому из 6 классов с помощью метода predict.</li>\n",
    "<p></p>\n",
    "  \n",
    "\n",
    " </ol> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение моделей\n",
    "def fit_models(X, Y, solver=None, max_iter=None):\n",
    "    # метод обучения:\n",
    "    if solver is None:\n",
    "        solver = 'lbfgs'\n",
    "    # максимальное количество итераций:\n",
    "    if max_iter is None:\n",
    "        max_iter = 100\n",
    "    # обучение моделей:\n",
    "    models = []\n",
    "    for y_col in Y.columns:\n",
    "        models.append(LogisticRegression(random_state=41, C=1,\n",
    "                                         solver=solver, max_iter=max_iter,\n",
    "                                         warm_start=True))\n",
    "        models[-1].fit(X, Y[y_col])\n",
    "        print('* Модель на ', y_col, ' обучена')\n",
    "    print('Обучение всех моделей завершено')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n"
     ]
    }
   ],
   "source": [
    "models = fit_models(comments_vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1, random_state=41, warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, warm_start=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models(X_test, models, p=None):\n",
    "    # p - NumPy массив размера 6 (число целевых признаков)\n",
    "    pred = np.array([]).reshape(X_test.shape[0], 0)\n",
    "    if p is None:\n",
    "        # p = тому, что выставит scikit-learn\n",
    "        for model in models:\n",
    "            pf = model.predict(X_test).reshape(-1, 1)\n",
    "            pred = np.hstack([pred, pf])\n",
    "        return pred\n",
    "    # p = пользовательскому значению\n",
    "    for model,pi in zip(models, p):\n",
    "        pp = (model.predict_proba(X_test)[:, 1] > pi).reshape(-1, 1)\n",
    "        # t[:, 1] вернет вероятности принадлежности к первому классу\n",
    "        pred = np.hstack([pred, pp])\n",
    "    # возвращается массив (Объект-Класс)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 143 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = comments_vec_test[52000:52003,:]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict_models(t, models)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 37 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = comments_vec_test[155,:]\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict_models(u, models)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.ones(6)* 0.1\n",
    "predict = predict_models(t, models, p=p)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([0.2, 0.05, 0.015, 0.05, 0.15, 0.07])\n",
    "predict = predict_models(t, models, p=p)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Оценка качества модели**\n",
    "Для оценки качества каждой из моделей воспользуемся $F$-мерой. Оценка качества по всем 6 классам будет проводиться по следующей формуле:\n",
    "$$F1=\\frac{1}{6}\\sum_{i=1}^6f1_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<h3> Задание 2.</h3>\n",
    "<p></p>\n",
    "\n",
    " <ol>\n",
    "  <li>Оценить качество полученной модели по всем 6 классам.</li>\n",
    " <p></p>\n",
    "\n",
    "      \n",
    "  <li>Провести преобразование текста с помощью метода CountVectorizer и построить модель логистической регрессии аналогично заданию 1. Какого качества удалось достичь?</li>\n",
    "<p></p>\n",
    "     \n",
    "  <li>Рассмотрите другие параметры Tf-Idf преобразования (lowercase, analyzer, stop_words, ngram_range, max_features) и попробуйте улучшить качество предсказаний.</li>\n",
    "<p></p>\n",
    "  \n",
    "\n",
    " </ol> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание по всем моделям (по всем классам)\n",
    "pred = predict_models(comments_vec_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепроверим размеры. Резульат предсказания - матрица (Объекты-Классы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52659, 30000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52659, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multy_f1_score(Y_test, pred):\n",
    "    y_cols = Y_test.columns\n",
    "    f1 = np.array([])\n",
    "    for i in range(y_cols.shape[0]):\n",
    "        score = f1_score(Y_test[y_cols[i]], pred[:, i])\n",
    "        f1 = np.hstack([f1, score])\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(multy_f):\n",
    "    # multy_f - NumPy array\n",
    "    return multy_f.sum() / multy_f.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73164947, 0.33748271, 0.73180077, 0.26086957, 0.62641509,\n",
       "       0.24113475])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multy_f1 = multy_f1_score(y_test, pred)\n",
    "multy_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48822539347524024"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = F1_score(multy_f1)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFidf 0.68 / 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразование данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_CV = CountVectorizer(max_features=30000,\n",
    "                               strip_accents='unicode', analyzer='word',\n",
    "                               token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_train_CV = count_vec_CV.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106912x30000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4701344 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_train_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_test_CV = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52659x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2307197 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_test_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение логистической регрессии**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В варианте данных, полученных ранее, логистическая регрессия не сходится. Воспользуемся методом `MaxAbsScaler` из sklearn для масштабирования разреженных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_transformer = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_cmnts_scaled_train = sparse_transformer.fit_transform(comments_vec_train_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106912x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4701344 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_cmnts_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_cmnts_scaled_test = sparse_transformer.transform(comments_vec_test_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52659x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2307197 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_cmnts_scaled_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование данных не помогает в случае обучения на `insult`. Попробуем применить метод `newton-cg` вместо стандартного метода `lbfgs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n"
     ]
    }
   ],
   "source": [
    "models_CV = fit_models(CV_cmnts_scaled_train, y_train, solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True),\n",
       " LogisticRegression(C=1, random_state=41, solver='newton-cg', warm_start=True)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение предсказания и проверка качетсва**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_CV = predict_models(CV_cmnts_scaled_test, models_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепроверка размеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52659, 30000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_cmnts_scaled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52659, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_CV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат - матрица (Объект-Класс)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00783546, 0.        , 0.00141193, 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multy_f1_CV = multy_f1_score(y_test, pred_CV)\n",
    "multy_f1_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015412310418728757"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_CV = F1_score(multy_f1_CV)\n",
    "F1_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили плохой результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение на немасштабированных данных, но с увеличением числа итераций**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию параметр `max_iter` (число итераций метода обучения) равен 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_CV = fit_models(comments_vec_train_CV, y_train, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_CV = predict_models(CV_cmnts_scaled_test, models_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multy_f1_CV = multy_f1_score(y_test, pred_CV)\n",
    "# multy_f1_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_CV = F1_score(multy_f1_CV)\n",
    "# F1_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 3**  \n",
    "Охватывается также и задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассмотрим гистограму (сверху) и примерно составим несколько\n",
    "# векторов вероятности\n",
    "p1 = np.array([0.15, 0.03, 0.1, 0.02, 0.1, 0.05])\n",
    "p2 = np.array([0.15, 0.05, 0.1, 0.01, 0.1, 0.05])\n",
    "p3 = np.array([0.2, 0.07, 0.15, 0.05, 0.15, 0.03])\n",
    "p4 = np.array([0.25, 0.06, 0.13, 0.03, 0.12, 0.025])\n",
    "p5 = np.array([0.17, 0.02, 0.11, 0.025, 0.9, 0.02])\n",
    "p6 = np.array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32])\n",
    "p7 = np.array([0.45, 0.3, 0.4, 0.27, 0.41, 0.27])\n",
    "\n",
    "params = {\n",
    "    'max_features': [25000, 30000, 35000, 40000],\n",
    "    'analyzer': ['word', 'char', 'char_wb'],\n",
    "    'lowercase': [True, False],\n",
    "    'stop_words': [{'english'}],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'p_for_classify': [p1, p2, p3, p4, p5, p6, p7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_params_sets(params):\n",
    "    params_list = []\n",
    "    for i in params['max_features']:\n",
    "        for j in params['analyzer']:\n",
    "            for k in params['lowercase']:\n",
    "                for z in params['ngram_range']:\n",
    "                    for l in params['stop_words']:\n",
    "                        for p in params['p_for_classify']:\n",
    "                            params_dict = {'max_features': i,\n",
    "                                           'analyzer': j,\n",
    "                                           'lowercase': k,\n",
    "                                           'ngram_range': z,\n",
    "                                           'stop_words': l,\n",
    "                                           'p_for_classify': p}\n",
    "                            params_list.append(params_dict)\n",
    "    return params_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число вариаций гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params = make_params_sets(params)\n",
    "len(all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число моделей, которые предстоит построить и обучить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3024"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_params) * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 30000,\n",
       " 'analyzer': 'char',\n",
       " 'lowercase': True,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stop_words': {'english'},\n",
       " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(params, X_train, X_test, Y_train, Y_test):\n",
    "    c_all = len(params)  # Общее число гиперпараметров\n",
    "    c = 0  # Счетчик для вывода номера итерации\n",
    "    tested_params = []\n",
    "    for par in params:\n",
    "        c += 1\n",
    "        print('-------| {}/{} |-------'.format(c, c_all))\n",
    "        print('Набор гиперпараметров:')\n",
    "        pprint(par)\n",
    "        # Данные\n",
    "        print('Преобразование данных в векторы:')\n",
    "        count_vec = TfidfVectorizer(max_features=par['max_features'],\n",
    "                                    analyzer=par['analyzer'],\n",
    "                                    lowercase=par['lowercase'],\n",
    "                                    ngram_range=par['ngram_range'],\n",
    "                                    stop_words=par['stop_words'],\n",
    "                                    sublinear_tf=True, \n",
    "                                    strip_accents='unicode', \n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "        comments_vec_train = count_vec.fit_transform(X_train)\n",
    "        print('* X_train преобразован')\n",
    "        comments_vec_test = count_vec.transform(X_test)\n",
    "        print('* X_test преобразован')\n",
    "        # Обучение моделей и проверка качества\n",
    "        print('Обучение моделей и проверка качества:')\n",
    "        models = fit_models(comments_vec_train, Y_train, max_iter=300)\n",
    "        # Проверка качества\n",
    "        predict = predict_models(comments_vec_test, models,\n",
    "                                 p=par['p_for_classify'])\n",
    "        multy_f1 = multy_f1_score(Y_test, predict)\n",
    "        F1 = F1_score(multy_f1)\n",
    "        # Добавление результатов в список\n",
    "        tested_params.append((par, multy_f1, F1))\n",
    "        print('Проверка гиперпараметров завершена.')\n",
    "    # Возвращается список кортежей из:\n",
    "    # набора параметров;\n",
    "    # f1 по всем признакам;\n",
    "    # F1 по f1.\n",
    "    return tested_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера обучим два набора гиперпарамертов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_features': 25000,\n",
       "  'analyzer': 'word',\n",
       "  'lowercase': True,\n",
       "  'ngram_range': (1, 1),\n",
       "  'stop_words': {'english'},\n",
       "  'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05])},\n",
       " {'max_features': 25000,\n",
       "  'analyzer': 'word',\n",
       "  'lowercase': True,\n",
       "  'ngram_range': (1, 1),\n",
       "  'stop_words': {'english'},\n",
       "  'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03])}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = all_params[1:3]\n",
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------| 1/2 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/2 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n"
     ]
    }
   ],
   "source": [
    "results = gridSearch(test_params, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1_score по наборам гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.537, 0.583]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: np.round(x[-1], 3), results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обучение по всем наборам гиперпараметров:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_now():\n",
    "    hs = int(time.strftime('%H')) * 3600\n",
    "    ms = int(time.strftime('%M')) * 60\n",
    "    s = int(time.strftime('%S'))\n",
    "    return hs + ms + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_GridSearch(all_params, X_train, X_test, Y_train, Y_test, k):\n",
    "    # Количество наборов гиперпараметров должно быть кратно k\n",
    "    all_results = []\n",
    "    total_time = 0\n",
    "    for i in range(0, len(all_params), k):  # пакеты гиперпараметров\n",
    "        params_batch = all_params[i:i+k]\n",
    "        print('\\n=====| Обработка пакета номер {}/{} |====='.format(int(i/k+1),\n",
    "                                                                  int(len(all_params)/k)))\n",
    "        s0 = time_now()  # расчет времени\n",
    "        try:\n",
    "            gs_res = gridSearch(params_batch,\n",
    "                                X_train, X_test,\n",
    "                                Y_train, Y_test)\n",
    "            for res_j in gs_res:\n",
    "                all_results.append(res_j)\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('\\nОбработка пакета {} завершена за {} секунд'.format(int(i/k+1), ds))\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\n!!! Выполнение было прервано пользователем')\n",
    "            break\n",
    "            # return -1\n",
    "        except:\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('!!! В пакете номер {} произошла ошибка. Пакет:'.format(int(i/k+1)))\n",
    "            pprint(params_batch)\n",
    "    h, m = int(total_time / 3600), int(total_time / 60) % 60\n",
    "    s = total_time - (h*3600 + m*60)\n",
    "    time_str = 'Общее время выполнения: {} секунд или {}ч:{}м:{}с'.format(\n",
    "        total_time, h, m, s\n",
    "    )\n",
    "    print(time_str)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**! Звезду смерти ниже лучше не запускать. Крайний раз работала 16ч:17м:4с.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====| Обработка пакета номер 1/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 1 завершена за 200 секунд\n",
      "\n",
      "=====| Обработка пакета номер 2/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 2 завершена за 333 секунд\n",
      "\n",
      "=====| Обработка пакета номер 3/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 3 завершена за 511 секунд\n",
      "\n",
      "=====| Обработка пакета номер 4/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 4 завершена за 377 секунд\n",
      "\n",
      "=====| Обработка пакета номер 5/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 5 завершена за 242 секунд\n",
      "\n",
      "=====| Обработка пакета номер 6/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 6 завершена за 406 секунд\n",
      "\n",
      "=====| Обработка пакета номер 7/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 7 завершена за 597 секунд\n",
      "\n",
      "=====| Обработка пакета номер 8/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 8 завершена за 205 секунд\n",
      "\n",
      "=====| Обработка пакета номер 9/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 9 завершена за 525 секунд\n",
      "\n",
      "=====| Обработка пакета номер 10/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 10 завершена за 1067 секунд\n",
      "\n",
      "=====| Обработка пакета номер 11/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 11 завершена за 732 секунд\n",
      "\n",
      "=====| Обработка пакета номер 12/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 12 завершена за 359 секунд\n",
      "\n",
      "=====| Обработка пакета номер 13/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 13 завершена за 753 секунд\n",
      "\n",
      "=====| Обработка пакета номер 14/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 14 завершена за 1297 секунд\n",
      "\n",
      "=====| Обработка пакета номер 15/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 15 завершена за 434 секунд\n",
      "\n",
      "=====| Обработка пакета номер 16/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 16 завершена за 808 секунд\n",
      "\n",
      "=====| Обработка пакета номер 17/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 17 завершена за 1272 секунд\n",
      "\n",
      "=====| Обработка пакета номер 18/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 18 завершена за 955 секунд\n",
      "\n",
      "=====| Обработка пакета номер 19/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 19 завершена за 624 секунд\n",
      "\n",
      "=====| Обработка пакета номер 20/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 20 завершена за 1027 секунд\n",
      "\n",
      "=====| Обработка пакета номер 21/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 21 завершена за 1510 секунд\n",
      "\n",
      "=====| Обработка пакета номер 22/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 22 завершена за 183 секунд\n",
      "\n",
      "=====| Обработка пакета номер 23/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 23 завершена за 351 секунд\n",
      "\n",
      "=====| Обработка пакета номер 24/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 24 завершена за 526 секунд\n",
      "\n",
      "=====| Обработка пакета номер 25/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 25 завершена за 393 секунд\n",
      "\n",
      "=====| Обработка пакета номер 26/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 26 завершена за 258 секунд\n",
      "\n",
      "=====| Обработка пакета номер 27/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 27 завершена за 431 секунд\n",
      "\n",
      "=====| Обработка пакета номер 28/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 28 завершена за 621 секунд\n",
      "\n",
      "=====| Обработка пакета номер 29/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 29 завершена за 208 секунд\n",
      "\n",
      "=====| Обработка пакета номер 30/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 30 завершена за 527 секунд\n",
      "\n",
      "=====| Обработка пакета номер 31/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 31 завершена за 1012 секунд\n",
      "\n",
      "=====| Обработка пакета номер 32/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 32 завершена за 712 секунд\n",
      "\n",
      "=====| Обработка пакета номер 33/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 33 завершена за 349 секунд\n",
      "\n",
      "=====| Обработка пакета номер 34/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 34 завершена за 737 секунд\n",
      "\n",
      "=====| Обработка пакета номер 35/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 35 завершена за 1306 секунд\n",
      "\n",
      "=====| Обработка пакета номер 36/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 36 завершена за 433 секунд\n",
      "\n",
      "=====| Обработка пакета номер 37/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 37 завершена за 808 секунд\n",
      "\n",
      "=====| Обработка пакета номер 38/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 38 завершена за 1295 секунд\n",
      "\n",
      "=====| Обработка пакета номер 39/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 39 завершена за 981 секунд\n",
      "\n",
      "=====| Обработка пакета номер 40/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 40 завершена за 627 секунд\n",
      "\n",
      "=====| Обработка пакета номер 41/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 41 завершена за 1052 секунд\n",
      "\n",
      "=====| Обработка пакета номер 42/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 42 завершена за 1560 секунд\n",
      "\n",
      "=====| Обработка пакета номер 43/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 43 завершена за 192 секунд\n",
      "\n",
      "=====| Обработка пакета номер 44/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 44 завершена за 356 секунд\n",
      "\n",
      "=====| Обработка пакета номер 45/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 45 завершена за 541 секунд\n",
      "\n",
      "=====| Обработка пакета номер 46/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 46 завершена за 408 секунд\n",
      "\n",
      "=====| Обработка пакета номер 47/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 47 завершена за 263 секунд\n",
      "\n",
      "=====| Обработка пакета номер 48/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 48 завершена за 430 секунд\n",
      "\n",
      "=====| Обработка пакета номер 49/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 49 завершена за 655 секунд\n",
      "\n",
      "=====| Обработка пакета номер 50/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 50 завершена за 215 секунд\n",
      "\n",
      "=====| Обработка пакета номер 51/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 51 завершена за 536 секунд\n",
      "\n",
      "=====| Обработка пакета номер 52/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 52 завершена за 1007 секунд\n",
      "\n",
      "=====| Обработка пакета номер 53/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 53 завершена за 823 секунд\n",
      "\n",
      "=====| Обработка пакета номер 54/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 54 завершена за 418 секунд\n",
      "\n",
      "=====| Обработка пакета номер 55/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 55 завершена за 902 секунд\n",
      "\n",
      "=====| Обработка пакета номер 56/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 56 завершена за 1600 секунд\n",
      "\n",
      "=====| Обработка пакета номер 57/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 57 завершена за 503 секунд\n",
      "\n",
      "=====| Обработка пакета номер 58/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 58 завершена за 897 секунд\n",
      "\n",
      "=====| Обработка пакета номер 59/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 59 завершена за 1272 секунд\n",
      "\n",
      "=====| Обработка пакета номер 60/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 60 завершена за 948 секунд\n",
      "\n",
      "=====| Обработка пакета номер 61/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 61 завершена за 601 секунд\n",
      "\n",
      "=====| Обработка пакета номер 62/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 62 завершена за 1072 секунд\n",
      "\n",
      "=====| Обработка пакета номер 63/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 63 завершена за 1587 секунд\n",
      "\n",
      "=====| Обработка пакета номер 64/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 64 завершена за 204 секунд\n",
      "\n",
      "=====| Обработка пакета номер 65/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 65 завершена за 365 секунд\n",
      "\n",
      "=====| Обработка пакета номер 66/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 66 завершена за 551 секунд\n",
      "\n",
      "=====| Обработка пакета номер 67/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 67 завершена за 412 секунд\n",
      "\n",
      "=====| Обработка пакета номер 68/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 68 завершена за 264 секунд\n",
      "\n",
      "=====| Обработка пакета номер 69/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 69 завершена за 439 секунд\n",
      "\n",
      "=====| Обработка пакета номер 70/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 70 завершена за 648 секунд\n",
      "\n",
      "=====| Обработка пакета номер 71/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 71 завершена за 201 секунд\n",
      "\n",
      "=====| Обработка пакета номер 72/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 72 завершена за 542 секунд\n",
      "\n",
      "=====| Обработка пакета номер 73/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 73 завершена за 1088 секунд\n",
      "\n",
      "=====| Обработка пакета номер 74/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 74 завершена за 763 секунд\n",
      "\n",
      "=====| Обработка пакета номер 75/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 75 завершена за 344 секунд\n",
      "\n",
      "=====| Обработка пакета номер 76/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 76 завершена за 733 секунд\n",
      "\n",
      "=====| Обработка пакета номер 77/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 77 завершена за 1317 секунд\n",
      "\n",
      "=====| Обработка пакета номер 78/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 78 завершена за 437 секунд\n",
      "\n",
      "=====| Обработка пакета номер 79/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 79 завершена за 825 секунд\n",
      "\n",
      "=====| Обработка пакета номер 80/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 80 завершена за 1345 секунд\n",
      "\n",
      "=====| Обработка пакета номер 81/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 81 завершена за 1033 секунд\n",
      "\n",
      "=====| Обработка пакета номер 82/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 82 завершена за 604 секунд\n",
      "\n",
      "=====| Обработка пакета номер 83/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 83 завершена за 1058 секунд\n",
      "\n",
      "=====| Обработка пакета номер 84/84 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и проверка качества:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 84 завершена за 1621 секунд\n",
      "Общее время выполнения: 58624 секунд или 16ч:17м:4с\n"
     ]
    }
   ],
   "source": [
    "bgs_results = batched_GridSearch(all_params, X_train, X_test, y_train, y_test, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76040306, 0.47563353, 0.78686281, 0.45697329, 0.72024836,\n",
      "       0.32598714]),\n",
      "  0.5876847000263816),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76161164, 0.46705054, 0.78836612, 0.44827586, 0.72086628,\n",
      "       0.32375741]),\n",
      "  0.5849879762365608),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76784219, 0.48178914, 0.799591  , 0.41509434, 0.71244052,\n",
      "       0.33001808]),\n",
      "  0.5844625445672542),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75730694, 0.4749512 , 0.78418621, 0.44970414, 0.71921352,\n",
      "       0.32010944]),\n",
      "  0.5842452417482644),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76084725, 0.46808511, 0.78590971, 0.44057971, 0.72077029,\n",
      "       0.32390511]),\n",
      "  0.5833495299378438),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76645257, 0.48152866, 0.79836512, 0.40860215, 0.71346023,\n",
      "       0.33063063]),\n",
      "  0.5831732285181165),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75997018, 0.47066327, 0.78688525, 0.43930636, 0.71950592,\n",
      "       0.32036199]),\n",
      "  0.5827821603088873),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76662636, 0.47933884, 0.80061454, 0.40419948, 0.71341256,\n",
      "       0.33168094]),\n",
      "  0.5826454539364737),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75742297, 0.47242051, 0.78458904, 0.44444444, 0.71709166,\n",
      "       0.31894593]),\n",
      "  0.5824857592471425),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.766769  , 0.48025478, 0.79938692, 0.40318302, 0.71353371,\n",
      "       0.33063063]),\n",
      "  0.582293010205516),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75682729, 0.4683871 , 0.78389903, 0.44508671, 0.71776406,\n",
      "       0.31910112]),\n",
      "  0.5818442173751914),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75702943, 0.46670976, 0.78390411, 0.43604651, 0.71696168,\n",
      "       0.31816133]),\n",
      "  0.5798021364574661),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77065868, 0.46126126, 0.78110028, 0.40167364, 0.70580687,\n",
      "       0.3001996 ]),\n",
      "  0.5701167218816839),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77890346, 0.47142857, 0.79110379, 0.375     , 0.70034954,\n",
      "       0.30138067]),\n",
      "  0.5696943378177363),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77913562, 0.46682464, 0.79059829, 0.37950664, 0.7015873 ,\n",
      "       0.29964609]),\n",
      "  0.5695497639799877),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76701649, 0.46387371, 0.77607007, 0.40677966, 0.70412586,\n",
      "       0.29835143]),\n",
      "  0.5693695373218325),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77869423, 0.46876859, 0.79157063, 0.375     , 0.69961856,\n",
      "       0.30240821]),\n",
      "  0.5693433700450994),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77044433, 0.46042296, 0.7789891 , 0.39655172, 0.70590122,\n",
      "       0.30012102]),\n",
      "  0.5687383919580977),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77027431, 0.4636472 , 0.78243645, 0.3877551 , 0.70458186,\n",
      "       0.30322324]),\n",
      "  0.5686530278195961),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76870884, 0.4589372 , 0.77933652, 0.40169133, 0.70478936,\n",
      "       0.29715659]),\n",
      "  0.5684366411190807),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.77777778, 0.46753247, 0.79165297, 0.37121212, 0.70114213,\n",
      "       0.2995283 ]),\n",
      "  0.5681409624046053),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75717439, 0.46428571, 0.76710963, 0.42196532, 0.70156719,\n",
      "       0.28996283]),\n",
      "  0.5670108456723496),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76621689, 0.46376812, 0.77454545, 0.3950104 , 0.70306729,\n",
      "       0.29718876]),\n",
      "  0.566632816615103),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76613145, 0.46469523, 0.77586777, 0.39240506, 0.7033424 ,\n",
      "       0.29608939]),\n",
      "  0.5664218817428299),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76515833, 0.46080192, 0.77695229, 0.38854806, 0.70417133,\n",
      "       0.29541864]),\n",
      "  0.565175092372581),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7548767 , 0.46740467, 0.76766667, 0.40935673, 0.69815745,\n",
      "       0.29045643]),\n",
      "  0.5646531089293911),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75575612, 0.46457178, 0.7663396 , 0.40697674, 0.70011708,\n",
      "       0.28961523]),\n",
      "  0.5638960914691059),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75648813, 0.46314496, 0.76649493, 0.40804598, 0.70016694,\n",
      "       0.28807264]),\n",
      "  0.5637355969043312),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73649814, 0.47139303, 0.77895445, 0.36579572, 0.70469799,\n",
      "       0.32480067]),\n",
      "  0.5636900004426572),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73584906, 0.47146402, 0.77867474, 0.36492891, 0.70503356,\n",
      "       0.32439229]),\n",
      "  0.5633904285206214),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73649814, 0.47110006, 0.77882353, 0.36492891, 0.70457977,\n",
      "       0.32439229]),\n",
      "  0.563387116266342),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73589697, 0.47080745, 0.77895445, 0.36492891, 0.70406967,\n",
      "       0.32439229]),\n",
      "  0.5631749564518617),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73511554, 0.47332078, 0.77597457, 0.359447  , 0.70603937,\n",
      "       0.32781316]),\n",
      "  0.5629517383071116),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73463839, 0.47361809, 0.77584476, 0.35862069, 0.70560748,\n",
      "       0.32767402]),\n",
      "  0.5626672391794652),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73463839, 0.47391578, 0.77641936, 0.35779817, 0.70584307,\n",
      "       0.32725731]),\n",
      "  0.5626453460427577),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73507834, 0.47391578, 0.77651388, 0.35616438, 0.70684474,\n",
      "       0.3271028 ]),\n",
      "  0.5626033222286333),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74594096, 0.46857143, 0.75423019, 0.41717791, 0.69704102,\n",
      "       0.2852263 ]),\n",
      "  0.5613646359834917),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74326189, 0.45982695, 0.7543183 , 0.42682927, 0.69722315,\n",
      "       0.28123676]),\n",
      "  0.5604493860616017),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74525346, 0.46105528, 0.75512261, 0.41463415, 0.69566678,\n",
      "       0.28425532]),\n",
      "  0.5593312638967849),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7414382 , 0.460199  , 0.7518898 , 0.42073171, 0.69522849,\n",
      "       0.28049299]),\n",
      "  0.5583300326916675),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74214418, 0.46115288, 0.75374516, 0.41717791, 0.69581301,\n",
      "       0.27827571]),\n",
      "  0.5580514773955705),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74357321, 0.4609619 , 0.75559294, 0.40483384, 0.69860948,\n",
      "       0.28461866]),\n",
      "  0.5580316701539053),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74288355, 0.46270544, 0.75202156, 0.40978593, 0.69430401,\n",
      "       0.27920962]),\n",
      "  0.5568183523304318),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73977147, 0.45629262, 0.75301609, 0.41543027, 0.69301625,\n",
      "       0.27574611]),\n",
      "  0.5555454671648742),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74974111, 0.40877598, 0.75989338, 0.36792453, 0.66562848,\n",
      "       0.38095238]),\n",
      "  0.5554859759056293),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75103448, 0.40877598, 0.75977882, 0.37558685, 0.66488652,\n",
      "       0.37202381]),\n",
      "  0.5553477446856196),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7483871 , 0.41657077, 0.76016427, 0.36018957, 0.66012489,\n",
      "       0.37967115]),\n",
      "  0.5541846252910508),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74804057, 0.41435185, 0.75959762, 0.35238095, 0.65922785,\n",
      "       0.37781109]),\n",
      "  0.5519016566437587),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72950542, 0.40195209, 0.75854668, 0.32771822, 0.68190705,\n",
      "       0.38696809]),\n",
      "  0.5477662580988732),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76880895, 0.41073512, 0.75788172, 0.32673267, 0.67193676,\n",
      "       0.34945398]),\n",
      "  0.5475915341361556),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76816533, 0.4126612 , 0.7570132 , 0.32835821, 0.67091109,\n",
      "       0.346875  ]),\n",
      "  0.547330670333711),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73833912, 0.39122958, 0.77263643, 0.29403606, 0.68259895,\n",
      "       0.40442133]),\n",
      "  0.547210245329557),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73749155, 0.39106145, 0.7712619 , 0.29558011, 0.68418695,\n",
      "       0.40337224]),\n",
      "  0.5471590336709686),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73885458, 0.39055794, 0.77078859, 0.29639889, 0.68416344,\n",
      "       0.4012945 ]),\n",
      "  0.5470096553797306),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73016679, 0.4       , 0.75851488, 0.32776935, 0.68097883,\n",
      "       0.38461538]),\n",
      "  0.5470075399418868),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73806103, 0.3888651 , 0.77135833, 0.29903978, 0.68426547,\n",
      "       0.4       ]),\n",
      "  0.546931617456247),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73590643, 0.43037975, 0.7489592 , 0.35294118, 0.65943503,\n",
      "       0.35151515]),\n",
      "  0.54652278941407),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73271599, 0.45624271, 0.75106174, 0.37150127, 0.68393614,\n",
      "       0.28204187]),\n",
      "  0.5462499531559033),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76929825, 0.40745052, 0.75806783, 0.31840796, 0.6736796 ,\n",
      "       0.3503876 ]),\n",
      "  0.5462152924638116),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73287794, 0.45560748, 0.75257227, 0.36868687, 0.68482871,\n",
      "       0.28205128]),\n",
      "  0.5461040917802088),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73330337, 0.45661037, 0.75106174, 0.36868687, 0.68491365,\n",
      "       0.28193833]),\n",
      "  0.5460857215945233),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72793433, 0.3966725 , 0.75824007, 0.32585949, 0.68210526,\n",
      "       0.3832021 ]),\n",
      "  0.5456689607554978),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73251843, 0.45571096, 0.75114304, 0.36775819, 0.68384151,\n",
      "       0.28225806]),\n",
      "  0.5455383648038524),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73338031, 0.42857143, 0.74765185, 0.3546798 , 0.65483504,\n",
      "       0.35312024]),\n",
      "  0.5453731128109099),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72839611, 0.39495433, 0.75851488, 0.3231441 , 0.6825158 ,\n",
      "       0.38366818]),\n",
      "  0.5451988998551717),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72488787, 0.39964711, 0.75448001, 0.33040936, 0.68303774,\n",
      "       0.37763158]),\n",
      "  0.5450156127460937),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76767455, 0.40705882, 0.75675676, 0.32      , 0.67061924,\n",
      "       0.34741784]),\n",
      "  0.5449212004920797),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72515016, 0.39805825, 0.75351682, 0.33383459, 0.68180442,\n",
      "       0.37557452]),\n",
      "  0.5446564598593755),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75029285, 0.45983702, 0.76696833, 0.31354642, 0.68477417,\n",
      "       0.29250457]),\n",
      "  0.5446538944961843),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74921814, 0.46091015, 0.76654827, 0.31212121, 0.68584759,\n",
      "       0.29229083]),\n",
      "  0.544489365717664),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73324847, 0.43137255, 0.76562818, 0.27225131, 0.66843736,\n",
      "       0.39592431]),\n",
      "  0.544477029403063),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73465556, 0.432     , 0.74786236, 0.33830846, 0.65455371,\n",
      "       0.35866261]),\n",
      "  0.5443404497585754),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73381961, 0.43090316, 0.76603543, 0.27225131, 0.66740527,\n",
      "       0.39534884]),\n",
      "  0.5442939365541895),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74965827, 0.46100116, 0.76610169, 0.3100304 , 0.68562549,\n",
      "       0.29271862]),\n",
      "  0.5441892723189173),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73328625, 0.42691415, 0.74759716, 0.34825871, 0.65222349,\n",
      "       0.35616438]),\n",
      "  0.5440740238436377),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73408933, 0.43090316, 0.76537678, 0.27225131, 0.66755319,\n",
      "       0.39358601]),\n",
      "  0.5439599625125732),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74902267, 0.46001168, 0.76699499, 0.30955994, 0.68543871,\n",
      "       0.29239766]),\n",
      "  0.5439042749198564),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76812874, 0.44631816, 0.75762901, 0.33891993, 0.68284389,\n",
      "       0.26936745]),\n",
      "  0.5438678634027796),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73292797, 0.43069874, 0.74524556, 0.33980583, 0.65638467,\n",
      "       0.35735736]),\n",
      "  0.5437366865677363),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73344074, 0.46135831, 0.75620104, 0.33729216, 0.69030887,\n",
      "       0.28362037]),\n",
      "  0.5437035853675309),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73401297, 0.4291939 , 0.76568867, 0.27225131, 0.66725781,\n",
      "       0.3930131 ]),\n",
      "  0.543569628314115),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76855037, 0.44960362, 0.75741542, 0.33395872, 0.68111455,\n",
      "       0.27036642]),\n",
      "  0.5435015182621172),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73461711, 0.46262507, 0.75554107, 0.33649289, 0.6899706 ,\n",
      "       0.28174168]),\n",
      "  0.5434980690595345),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73419309, 0.46162859, 0.75603392, 0.33490566, 0.68985791,\n",
      "       0.28278388]),\n",
      "  0.5432338417812239),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73433584, 0.46298472, 0.7553816 , 0.33411765, 0.6899706 ,\n",
      "       0.2818448 ]),\n",
      "  0.5431058692325386),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7674784 , 0.44858757, 0.7572319 , 0.33088235, 0.68248798,\n",
      "       0.27034678]),\n",
      "  0.5428358300210719),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.76734373, 0.44619718, 0.75599616, 0.33457249, 0.68221124,\n",
      "       0.26846591]),\n",
      "  0.5424644535877993),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75435471, 0.44585987, 0.74565357, 0.36631579, 0.67925706,\n",
      "       0.26319648]),\n",
      "  0.542439581724195),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75085191, 0.46941176, 0.76445017, 0.29386591, 0.6854212 ,\n",
      "       0.28979144]),\n",
      "  0.5422987317698356),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75090042, 0.46961652, 0.76524537, 0.29022989, 0.68606098,\n",
      "       0.29020468]),\n",
      "  0.5420429764100804),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7506812 , 0.46851089, 0.76497102, 0.29184549, 0.68563433,\n",
      "       0.28957952]),\n",
      "  0.5418704096822573),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75114355, 0.46843658, 0.76489533, 0.29022989, 0.68594527,\n",
      "       0.29041697]),\n",
      "  0.5418445984591557),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75512833, 0.44085401, 0.74569174, 0.36625514, 0.67928069,\n",
      "       0.26281113]),\n",
      "  0.5416701733022381),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72469396, 0.39493228, 0.75195103, 0.31988473, 0.67934209,\n",
      "       0.37904269]),\n",
      "  0.541641130647674),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73456647, 0.43506494, 0.76901294, 0.2459893 , 0.6688771 ,\n",
      "       0.39255014]),\n",
      "  0.5410101503380143),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75416336, 0.44289855, 0.74666667, 0.35833333, 0.67978757,\n",
      "       0.26358297]),\n",
      "  0.5409054076245109),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73454293, 0.43506494, 0.76901294, 0.24468085, 0.6678453 ,\n",
      "       0.39311334]),\n",
      "  0.5407100518274854),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75145881, 0.44380403, 0.74449976, 0.36363636, 0.6803253 ,\n",
      "       0.25912409]),\n",
      "  0.540474726189388),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73459003, 0.43213898, 0.76826553, 0.24468085, 0.66799293,\n",
      "       0.39311334]),\n",
      "  0.5401302774105646),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7343118 , 0.43213898, 0.76826553, 0.24468085, 0.66799293,\n",
      "       0.39311334]),\n",
      "  0.5400839054357708),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72472574, 0.39253148, 0.75294118, 0.31444759, 0.67867327,\n",
      "       0.37668161]),\n",
      "  0.5400001453768365),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75803235, 0.41607565, 0.74623746, 0.32085561, 0.66488294,\n",
      "       0.33173844]),\n",
      "  0.5396370757361489),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75052202, 0.44483363, 0.74302307, 0.35639413, 0.67784394,\n",
      "       0.26070901]),\n",
      "  0.5388876323842114),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72949184, 0.42044135, 0.74445839, 0.34482759, 0.65543924,\n",
      "       0.33538462]),\n",
      "  0.5383405022460089),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73833912, 0.4565811 , 0.77263643, 0.17473118, 0.68259895,\n",
      "       0.40442133]),\n",
      "  0.5382180197155222),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73885458, 0.4576734 , 0.77078859, 0.17431803, 0.68416344,\n",
      "       0.4012945 ]),\n",
      "  0.5378487555858675),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73749155, 0.4565811 , 0.7712619 , 0.17333333, 0.68418695,\n",
      "       0.40337224]),\n",
      "  0.5377045125950373),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74809009, 0.44483159, 0.74299517, 0.35196687, 0.67720726,\n",
      "       0.26022853]),\n",
      "  0.5375532525310392),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73806103, 0.45494028, 0.77135833, 0.17611741, 0.68426547,\n",
      "       0.4       ]),\n",
      "  0.5374570869610101),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74624803, 0.43933295, 0.74268253, 0.36078431, 0.67760588,\n",
      "       0.25544267]),\n",
      "  0.5370160616675594),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74730064, 0.43956044, 0.74150427, 0.35412475, 0.67773254,\n",
      "       0.25915081]),\n",
      "  0.5365622408557543),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72938963, 0.42508711, 0.74550021, 0.33663366, 0.6522037 ,\n",
      "       0.32872504]),\n",
      "  0.5362565576234153),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7284737 , 0.42709529, 0.74217273, 0.32835821, 0.65091743,\n",
      "       0.33333333]),\n",
      "  0.5350584480395311),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75666075, 0.42130178, 0.74591879, 0.28877005, 0.66308003,\n",
      "       0.32956381]),\n",
      "  0.5342158681004767),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72950542, 0.45576708, 0.75854668, 0.18740849, 0.68190705,\n",
      "       0.38696809]),\n",
      "  0.5333504681738014),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73016679, 0.45251397, 0.75851488, 0.18604651, 0.68097883,\n",
      "       0.38461538]),\n",
      "  0.5321393950439114),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75800712, 0.41190476, 0.74465409, 0.2962963 , 0.66188983,\n",
      "       0.31921824]),\n",
      "  0.5319950565058447),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72793433, 0.45175683, 0.75824007, 0.18664752, 0.68210526,\n",
      "       0.3832021 ]),\n",
      "  0.5316476873052999),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72839611, 0.4553473 , 0.75851488, 0.18106427, 0.6825158 ,\n",
      "       0.38366818]),\n",
      "  0.531584422675231),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74810668, 0.42600897, 0.76382935, 0.20994475, 0.67595212,\n",
      "       0.35419847]),\n",
      "  0.5296733920503581),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7580753 , 0.41527446, 0.74502409, 0.27807487, 0.66083838,\n",
      "       0.32038835]),\n",
      "  0.5296125741507756),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72488787, 0.45316882, 0.75448001, 0.18296974, 0.68303774,\n",
      "       0.37763158]),\n",
      "  0.5293626275422706),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74827246, 0.42247191, 0.763131  , 0.20994475, 0.67552844,\n",
      "       0.35670732]),\n",
      "  0.5293426462757674),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7483262 , 0.42069741, 0.76303414, 0.20994475, 0.67407892,\n",
      "       0.35670732]),\n",
      "  0.5287981239012944),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72515016, 0.4503386 , 0.75351682, 0.18601298, 0.68180442,\n",
      "       0.37557452]),\n",
      "  0.5287329163939957),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74876523, 0.41891892, 0.76252812, 0.20994475, 0.67350502,\n",
      "       0.35725191]),\n",
      "  0.5284856585907038),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72469396, 0.45434298, 0.75195103, 0.18004187, 0.67934209,\n",
      "       0.37904269]),\n",
      "  0.5282357712388152),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75601375, 0.40617577, 0.743348  , 0.2826087 , 0.6611385 ,\n",
      "       0.31511254]),\n",
      "  0.527399542599418),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74885246, 0.42857143, 0.76591418, 0.1920904 , 0.67612396,\n",
      "       0.35240964]),\n",
      "  0.5273270100445336),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72472574, 0.45283019, 0.75294118, 0.17805383, 0.67867327,\n",
      "       0.37668161]),\n",
      "  0.5273176364037736),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7553085 , 0.41296519, 0.74248476, 0.27472527, 0.66096353,\n",
      "       0.3171521 ]),\n",
      "  0.5272665597213285),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74844211, 0.42857143, 0.76616511, 0.1920904 , 0.67496723,\n",
      "       0.35240964]),\n",
      "  0.5271076528569071),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74830527, 0.42600897, 0.765412  , 0.19101124, 0.67424574,\n",
      "       0.35488722]),\n",
      "  0.5266450722526153),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7544016 , 0.424821  , 0.73892872, 0.26373626, 0.65929603,\n",
      "       0.31818182]),\n",
      "  0.5265609066465669),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74830527, 0.42600897, 0.76591418, 0.19101124, 0.67438811,\n",
      "       0.35240964]),\n",
      "  0.5263395667301358),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75383248, 0.41281139, 0.7429171 , 0.27322404, 0.6583991 ,\n",
      "       0.31663974]),\n",
      "  0.5263039761285708),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70222513, 0.39913978, 0.7396485 , 0.22334004, 0.66162571,\n",
      "       0.41676792]),\n",
      "  0.5237911804798027),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7049959 , 0.39674379, 0.73710879, 0.2168906 , 0.6616169 ,\n",
      "       0.42251816]),\n",
      "  0.5233123562421259),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7045138 , 0.3963964 , 0.73706189, 0.2164751 , 0.66103423,\n",
      "       0.42424242]),\n",
      "  0.5232873076163477),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70240629, 0.39948343, 0.74001193, 0.22087133, 0.6621071 ,\n",
      "       0.41484185]),\n",
      "  0.5232869860255126),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7046683 , 0.39708405, 0.73758019, 0.21455939, 0.66113295,\n",
      "       0.42207398]),\n",
      "  0.5228498110980445),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70168549, 0.39982766, 0.74001193, 0.21840243, 0.66230176,\n",
      "       0.41433779]),\n",
      "  0.5227611745873993),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70185776, 0.39982766, 0.73968112, 0.21796165, 0.66210511,\n",
      "       0.41484185]),\n",
      "  0.5227125262495192),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70477438, 0.39708405, 0.7371403 , 0.21497121, 0.66094046,\n",
      "       0.4203513 ]),\n",
      "  0.5225436169230017),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72606505, 0.45614035, 0.75758819, 0.16      , 0.66562778,\n",
      "       0.35204856]),\n",
      "  0.5195783211935653),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72516898, 0.45365322, 0.75656814, 0.16091954, 0.66607302,\n",
      "       0.34954407]),\n",
      "  0.5186544950604343),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74722945, 0.44252563, 0.73790952, 0.26609442, 0.6646553 ,\n",
      "       0.25318878]),\n",
      "  0.5186005164670153),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74725698, 0.44300378, 0.73748245, 0.2633864 , 0.66475645,\n",
      "       0.25255102]),\n",
      "  0.5180728459274723),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74684884, 0.44192328, 0.73751561, 0.26354319, 0.66475558,\n",
      "       0.25279285]),\n",
      "  0.5178965592086267),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74687199, 0.44300378, 0.73717049, 0.26224784, 0.66505733,\n",
      "       0.25239617]),\n",
      "  0.5177912665904701),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72529486, 0.45514223, 0.75641289, 0.16091954, 0.66473344,\n",
      "       0.34398782]),\n",
      "  0.5177484631613871),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7247439 , 0.36553945, 0.72989018, 0.26597132, 0.66077636,\n",
      "       0.35652174]),\n",
      "  0.5172404907488172),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7264615 , 0.4495614 , 0.75721006, 0.14942529, 0.66533422,\n",
      "       0.35469449]),\n",
      "  0.5171144941675486),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74539524, 0.4474687 , 0.74082175, 0.24687933, 0.66576087,\n",
      "       0.2553327 ]),\n",
      "  0.5169430979557067),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72410922, 0.36591276, 0.72974974, 0.2622108 , 0.66011277,\n",
      "       0.35945274]),\n",
      "  0.5169246710614596),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7456847 , 0.44673913, 0.74116912, 0.24687933, 0.665157  ,\n",
      "       0.25541401]),\n",
      "  0.5168405487771431),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74575621, 0.44637997, 0.74057858, 0.24756606, 0.66465439,\n",
      "       0.25598468]),\n",
      "  0.5168199815300069),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72594118, 0.45076586, 0.75771826, 0.15028902, 0.66547963,\n",
      "       0.3502994 ]),\n",
      "  0.5167488931809484),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74563591, 0.44673913, 0.74078701, 0.2461964 , 0.66435569,\n",
      "       0.25588797]),\n",
      "  0.5166003519372261),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72608696, 0.45027322, 0.75736498, 0.15028902, 0.66518255,\n",
      "       0.34730539]),\n",
      "  0.5160836848879853),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72589879, 0.45196507, 0.75730934, 0.15028902, 0.66548043,\n",
      "       0.34534535]),\n",
      "  0.516047997546586),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72491047, 0.36546185, 0.72902176, 0.25954198, 0.66079677,\n",
      "       0.3560794 ]),\n",
      "  0.5159687045737483),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7045138 , 0.44983819, 0.73706189, 0.11901441, 0.66103423,\n",
      "       0.42424242]),\n",
      "  0.5159508255199926),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7046683 , 0.44983819, 0.73758019, 0.11890386, 0.66113295,\n",
      "       0.42207398]),\n",
      "  0.5156995790626391),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7049959 , 0.44922085, 0.73710879, 0.11829945, 0.6616169 ,\n",
      "       0.42251816]),\n",
      "  0.5156266749051883),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7244711 , 0.36524537, 0.73031875, 0.25814536, 0.66126465,\n",
      "       0.35323077]),\n",
      "  0.5154460016181347),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70222513, 0.45112782, 0.7396485 , 0.12126866, 0.66162571,\n",
      "       0.41676792]),\n",
      "  0.5154439556594035),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72506584, 0.45365322, 0.75631287, 0.15028902, 0.66413916,\n",
      "       0.34250765]),\n",
      "  0.5153279592306428),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70240629, 0.45099089, 0.74001193, 0.12126866, 0.6621071 ,\n",
      "       0.41484185]),\n",
      "  0.5152711189157976),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70185776, 0.45147453, 0.73968112, 0.12115564, 0.66210511,\n",
      "       0.41484185]),\n",
      "  0.5151860018900031),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70477438, 0.44935345, 0.7371403 , 0.11840888, 0.66094046,\n",
      "       0.4203513 ]),\n",
      "  0.5151614622065709),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70168549, 0.45074946, 0.74001193, 0.12087401, 0.66230176,\n",
      "       0.41433779]),\n",
      "  0.5149934061825155),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73512387, 0.41627907, 0.73425115, 0.23280423, 0.64743012,\n",
      "       0.32339089]),\n",
      "  0.5148798888579631),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71336621, 0.37172557, 0.717465  , 0.27848101, 0.65723866,\n",
      "       0.342711  ]),\n",
      "  0.5134979091930866),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71145651, 0.37213183, 0.71583   , 0.27769986, 0.65641026,\n",
      "       0.34190231]),\n",
      "  0.5125717946848521),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74297494, 0.44792833, 0.75437513, 0.14285714, 0.672221  ,\n",
      "       0.31340872]),\n",
      "  0.5122942114222289),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71259185, 0.3714167 , 0.71717023, 0.27235213, 0.65683411,\n",
      "       0.34180432]),\n",
      "  0.5120282240837943),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73532823, 0.4121071 , 0.73216521, 0.22580645, 0.64857531,\n",
      "       0.31761006]),\n",
      "  0.5119320596159042),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71177945, 0.37095436, 0.71675277, 0.2688172 , 0.65693857,\n",
      "       0.34408602]),\n",
      "  0.5115547276421802),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74261512, 0.44618834, 0.75458479, 0.13253012, 0.67355009,\n",
      "       0.31493506]),\n",
      "  0.5107339207164242),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74247855, 0.44719101, 0.75442934, 0.13173653, 0.67251975,\n",
      "       0.31442464]),\n",
      "  0.5104633022073977),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73465599, 0.40797186, 0.73171751, 0.22580645, 0.64707212,\n",
      "       0.31528662]),\n",
      "  0.5104184274660859),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71019454, 0.37073982, 0.71343991, 0.2739726 , 0.65583845,\n",
      "       0.33826367]),\n",
      "  0.5104081641744723),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74272107, 0.44792833, 0.75728953, 0.11976048, 0.67192291,\n",
      "       0.32268371]),\n",
      "  0.5103843377438289),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74218071, 0.44618834, 0.7548959 , 0.13253012, 0.67253134,\n",
      "       0.31219512]),\n",
      "  0.510086922126994),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71125585, 0.36874742, 0.71453901, 0.26790451, 0.65480531,\n",
      "       0.34155598]),\n",
      "  0.5098013438934413),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73533852, 0.40983607, 0.73247078, 0.21621622, 0.64720525,\n",
      "       0.31528662]),\n",
      "  0.5093922435314148),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74245538, 0.44568869, 0.75692308, 0.11976048, 0.67163852,\n",
      "       0.31897927]),\n",
      "  0.5092409017713636),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70960207, 0.3695742 , 0.71179427, 0.27445652, 0.65536393,\n",
      "       0.3335439 ]),\n",
      "  0.5090558154940358),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74185518, 0.44692737, 0.75600246, 0.11976048, 0.67178587,\n",
      "       0.31089744]),\n",
      "  0.5078714669862929),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7423439 , 0.44618834, 0.75590228, 0.11976048, 0.67178587,\n",
      "       0.31089744]),\n",
      "  0.5078130512850872),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75505272, 0.41141498, 0.73039832, 0.19565217, 0.65437583,\n",
      "       0.29850746]),\n",
      "  0.5075669164425517),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7247439 , 0.42424242, 0.72989018, 0.14530892, 0.66077636,\n",
      "       0.35652174]),\n",
      "  0.5069139206509508),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72410922, 0.42240493, 0.72974974, 0.14505997, 0.66011277,\n",
      "       0.35945274]),\n",
      "  0.5068148943105938),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72491047, 0.42386831, 0.72902176, 0.14472934, 0.66079677,\n",
      "       0.3560794 ]),\n",
      "  0.5065676754677756),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7244711 , 0.42169908, 0.73031875, 0.14463277, 0.66126465,\n",
      "       0.35323077]),\n",
      "  0.5059361865632714),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70646021, 0.36942149, 0.70947741, 0.27440633, 0.65202211,\n",
      "       0.32294264]),\n",
      "  0.5057883659760823),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71336621, 0.42902542, 0.717465  , 0.16045483, 0.65723866,\n",
      "       0.342711  ]),\n",
      "  0.5033768545166449),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75514019, 0.40430622, 0.72876023, 0.1878453 , 0.65448875,\n",
      "       0.28714524]),\n",
      "  0.5029476549641907),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71259185, 0.42834479, 0.71717023, 0.1584529 , 0.65683411,\n",
      "       0.34180432]),\n",
      "  0.5025330338486881),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71779213, 0.41536615, 0.71845893, 0.20338983, 0.63777372,\n",
      "       0.32012678]),\n",
      "  0.5021512578532051),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71177945, 0.42797056, 0.71675277, 0.15517241, 0.65693857,\n",
      "       0.34408602]),\n",
      "  0.5021166293011221),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71145651, 0.42727757, 0.71583   , 0.158831  , 0.65641026,\n",
      "       0.34190231]),\n",
      "  0.501951275218149),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71125585, 0.42722513, 0.71453901, 0.15449608, 0.65480531,\n",
      "       0.34155598]),\n",
      "  0.5006462243211995),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71019454, 0.42690678, 0.71343991, 0.15576324, 0.65583845,\n",
      "       0.33826367]),\n",
      "  0.5000677641199429),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70960207, 0.42609153, 0.71179427, 0.15365551, 0.65536393,\n",
      "       0.3335439 ]),\n",
      "  0.49834186867200886),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71629114, 0.41050119, 0.71574035, 0.20338983, 0.63904784,\n",
      "       0.30273752]),\n",
      "  0.4979513116036651),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71509434, 0.40384615, 0.71816638, 0.21590909, 0.63669725,\n",
      "       0.29773463]),\n",
      "  0.497907973936202),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71580439, 0.40243902, 0.71768707, 0.21590909, 0.63878676,\n",
      "       0.29593496]),\n",
      "  0.4977602180385863),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7548621 , 0.39711191, 0.72948583, 0.16853933, 0.65297925,\n",
      "       0.28140704]),\n",
      "  0.49739757622557046),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71086469, 0.40145103, 0.71462013, 0.21111111, 0.63435921,\n",
      "       0.3072    ]),\n",
      "  0.49660102891420715),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70280344, 0.36449332, 0.7114171 , 0.18307427, 0.64419263,\n",
      "       0.36135371]),\n",
      "  0.4945557445949216),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70646021, 0.42459275, 0.70947741, 0.15168196, 0.65202211,\n",
      "       0.32294264]),\n",
      "  0.49452951354634617),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75288938, 0.39328537, 0.72845734, 0.15819209, 0.65253292,\n",
      "       0.28140704]),\n",
      "  0.49446068785735386),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70172595, 0.36634051, 0.70838117, 0.18716578, 0.64046374,\n",
      "       0.36183122]),\n",
      "  0.49431806061955114),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70178282, 0.36534692, 0.70882437, 0.18518519, 0.64164306,\n",
      "       0.36243094]),\n",
      "  0.4942022169324612),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70300965, 0.36484896, 0.71043578, 0.18275862, 0.64363585,\n",
      "       0.35986914]),\n",
      "  0.49409300029554193),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70309713, 0.36435022, 0.71062061, 0.18291631, 0.64355455,\n",
      "       0.35956284]),\n",
      "  0.4940169424013196),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70309713, 0.36470588, 0.71055651, 0.1832325 , 0.64364563,\n",
      "       0.35866594]),\n",
      "  0.4939839310758633),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70214662, 0.36399217, 0.70753769, 0.18783542, 0.64147205,\n",
      "       0.35911602]),\n",
      "  0.4936833277507106),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70205008, 0.36442006, 0.70772323, 0.18733274, 0.6403397 ,\n",
      "       0.35951327]),\n",
      "  0.49356318041679453),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71408451, 0.41013269, 0.71598135, 0.20879121, 0.63652968,\n",
      "       0.27540984]),\n",
      "  0.49348821171351603),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70731707, 0.40533981, 0.71337308, 0.20454545, 0.63245109,\n",
      "       0.29545455]),\n",
      "  0.4930801759469765),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74266091, 0.4004884 , 0.7161071 , 0.1754386 , 0.6430984 ,\n",
      "       0.27749577]),\n",
      "  0.4925481952691846),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74377421, 0.40736196, 0.71492442, 0.1754386 , 0.64469526,\n",
      "       0.26530612]),\n",
      "  0.49191676216110575),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70280344, 0.42642643, 0.7114171 , 0.10342084, 0.64419263,\n",
      "       0.36135371]),\n",
      "  0.4916023580730655),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70780916, 0.40920097, 0.71309549, 0.20338983, 0.63053506,\n",
      "       0.28431373]),\n",
      "  0.4913907057342722),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70300965, 0.42521261, 0.71043578, 0.10383387, 0.64363585,\n",
      "       0.35986914]),\n",
      "  0.490999482137471),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70309713, 0.42394015, 0.71062061, 0.10358566, 0.64355455,\n",
      "       0.35956284]),\n",
      "  0.49072682305045046),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70309713, 0.42457542, 0.71055651, 0.10350318, 0.64364563,\n",
      "       0.35866594]),\n",
      "  0.4906739692586332),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70178282, 0.424     , 0.70882437, 0.10458046, 0.64164306,\n",
      "       0.36243094]),\n",
      "  0.49054360928898605),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74218577, 0.39900867, 0.71468144, 0.17647059, 0.64628623,\n",
      "       0.26369863]),\n",
      "  0.49038855548725496),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74097122, 0.4       , 0.71452991, 0.1754386 , 0.64655172,\n",
      "       0.26369863]),\n",
      "  0.4901983473867327),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70172595, 0.4241517 , 0.70838117, 0.10458046, 0.64046374,\n",
      "       0.36183122]),\n",
      "  0.4901890397027462),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70214662, 0.4241517 , 0.70753769, 0.10551948, 0.64147205,\n",
      "       0.35911602]),\n",
      "  0.48999059183760335),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.70205008, 0.42372881, 0.70772323, 0.10526316, 0.6403397 ,\n",
      "       0.35951327]),\n",
      "  0.48976970877211246),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61948915, 0.45369795, 0.67136451, 0.29175476, 0.60470472,\n",
      "       0.25964392]),\n",
      "  0.4834425011960755),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61948915, 0.45369795, 0.67136451, 0.29175476, 0.60470472,\n",
      "       0.25964392]),\n",
      "  0.4834425011960755),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61948915, 0.45369795, 0.67136451, 0.29175476, 0.60470472,\n",
      "       0.25964392]),\n",
      "  0.4834425011960755),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61948915, 0.45369795, 0.67136451, 0.29175476, 0.60470472,\n",
      "       0.25964392]),\n",
      "  0.4834425011960755),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62104618, 0.4484472 , 0.67073171, 0.30084746, 0.60315375,\n",
      "       0.25595238]),\n",
      "  0.4833631118919653),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62104618, 0.4484472 , 0.67073171, 0.30084746, 0.60315375,\n",
      "       0.25595238]),\n",
      "  0.4833631118919653),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62104618, 0.4484472 , 0.67073171, 0.30084746, 0.60315375,\n",
      "       0.25595238]),\n",
      "  0.4833631118919653),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62104618, 0.4484472 , 0.67073171, 0.30084746, 0.60315375,\n",
      "       0.25595238]),\n",
      "  0.4833631118919653),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73734564, 0.39506173, 0.70797599, 0.15568862, 0.63912846,\n",
      "       0.26116838]),\n",
      "  0.48272813802887765),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74035477, 0.38964242, 0.7114237 , 0.17241379, 0.64351747,\n",
      "       0.23793103]),\n",
      "  0.48254719768133464),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73774319, 0.38653367, 0.71111111, 0.15384615, 0.63978251,\n",
      "       0.26324786]),\n",
      "  0.4820440824828088),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73699454, 0.39702233, 0.71045289, 0.15568862, 0.63983629,\n",
      "       0.24784854]),\n",
      "  0.4813072016633595),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63804861, 0.43942029, 0.66456891, 0.29501085, 0.60244059,\n",
      "       0.23373984]),\n",
      "  0.478871514213685),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63804861, 0.43942029, 0.66456891, 0.29501085, 0.60244059,\n",
      "       0.23373984]),\n",
      "  0.478871514213685),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63804861, 0.43942029, 0.66456891, 0.29501085, 0.60244059,\n",
      "       0.23373984]),\n",
      "  0.478871514213685),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63804861, 0.43942029, 0.66456891, 0.29501085, 0.60244059,\n",
      "       0.23373984]),\n",
      "  0.478871514213685),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63837606, 0.43695526, 0.66498978, 0.29345372, 0.59977524,\n",
      "       0.2336163 ]),\n",
      "  0.47786106153138813),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63837606, 0.43695526, 0.66498978, 0.29345372, 0.59977524,\n",
      "       0.2336163 ]),\n",
      "  0.47786106153138813),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63837606, 0.43695526, 0.66498978, 0.29345372, 0.59977524,\n",
      "       0.2336163 ]),\n",
      "  0.47786106153138813),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63837606, 0.43695526, 0.66498978, 0.29345372, 0.59977524,\n",
      "       0.2336163 ]),\n",
      "  0.47786106153138813),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7513666 , 0.33251145, 0.78188131, 0.34210526, 0.36258731,\n",
      "       0.26987308]),\n",
      "  0.4733875019820224),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.75216087, 0.33227737, 0.78079596, 0.34042553, 0.36468447,\n",
      "       0.26942314]),\n",
      "  0.4732945563471696),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7530886 , 0.33227737, 0.78185267, 0.3360522 , 0.36776734,\n",
      "       0.26808936]),\n",
      "  0.47318792432191964),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74476765, 0.34097421, 0.7703937 , 0.36567164, 0.34382716,\n",
      "       0.2714625 ]),\n",
      "  0.4728494779084038),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7534162 , 0.3315771 , 0.78083491, 0.33278956, 0.36529126,\n",
      "       0.26826827]),\n",
      "  0.4720295511808268),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74260931, 0.33677465, 0.76940063, 0.35906643, 0.35398773,\n",
      "       0.26932163]),\n",
      "  0.4718600643381233),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74439621, 0.33808845, 0.76940028, 0.36162362, 0.34729064,\n",
      "       0.27014218]),\n",
      "  0.4718235621935234),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61945828, 0.41364136, 0.69003378, 0.2       , 0.58360656,\n",
      "       0.3196347 ]),\n",
      "  0.4710624476927762),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61945828, 0.41364136, 0.69003378, 0.2       , 0.58360656,\n",
      "       0.3196347 ]),\n",
      "  0.4710624476927762),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61945828, 0.41364136, 0.69003378, 0.2       , 0.58360656,\n",
      "       0.3196347 ]),\n",
      "  0.4710624476927762),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61945828, 0.41364136, 0.69003378, 0.2       , 0.58360656,\n",
      "       0.3196347 ]),\n",
      "  0.4710624476927762),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74210945, 0.33687943, 0.76971609, 0.35211268, 0.35377069,\n",
      "       0.26751167]),\n",
      "  0.4703500025435954),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74139   , 0.33675274, 0.76435331, 0.3605948 , 0.34870849,\n",
      "       0.2683339 ]),\n",
      "  0.4700222047514488),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74029534, 0.33368607, 0.76361347, 0.36297641, 0.35355392,\n",
      "       0.26538078]),\n",
      "  0.4699176641882173),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74153329, 0.33581825, 0.76519817, 0.35701275, 0.35012285,\n",
      "       0.26904922]),\n",
      "  0.4697890886462259),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61607686, 0.42529989, 0.68835834, 0.17777778, 0.58598131,\n",
      "       0.31818182]),\n",
      "  0.46861266466802154),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61607686, 0.42529989, 0.68835834, 0.17777778, 0.58598131,\n",
      "       0.31818182]),\n",
      "  0.46861266466802154),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61607686, 0.42529989, 0.68835834, 0.17777778, 0.58598131,\n",
      "       0.31818182]),\n",
      "  0.46861266466802154),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.61607686, 0.42529989, 0.68835834, 0.17777778, 0.58598131,\n",
      "       0.31818182]),\n",
      "  0.46861266466802154),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73891973, 0.33123249, 0.76368785, 0.3556338 , 0.35736103,\n",
      "       0.26441352]),\n",
      "  0.46854140392916954),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63255603, 0.42      , 0.68609103, 0.16470588, 0.59021689,\n",
      "       0.29855538]),\n",
      "  0.46535420131198135),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63255603, 0.42      , 0.68609103, 0.16470588, 0.59021689,\n",
      "       0.29855538]),\n",
      "  0.46535420131198135),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63255603, 0.42      , 0.68609103, 0.16470588, 0.59021689,\n",
      "       0.29855538]),\n",
      "  0.46535420131198135),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63255603, 0.42      , 0.68609103, 0.16470588, 0.59021689,\n",
      "       0.29855538]),\n",
      "  0.46535420131198135),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63244771, 0.40723982, 0.68663692, 0.16470588, 0.58883249,\n",
      "       0.3022508 ]),\n",
      "  0.46368560447119833),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63244771, 0.40723982, 0.68663692, 0.16470588, 0.58883249,\n",
      "       0.3022508 ]),\n",
      "  0.46368560447119833),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63244771, 0.40723982, 0.68663692, 0.16470588, 0.58883249,\n",
      "       0.3022508 ]),\n",
      "  0.46368560447119833),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63244771, 0.40723982, 0.68663692, 0.16470588, 0.58883249,\n",
      "       0.3022508 ]),\n",
      "  0.46368560447119833),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62575956, 0.43973214, 0.68871925, 0.12941176, 0.58924831,\n",
      "       0.29107981]),\n",
      "  0.4606584746150136),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62575956, 0.43973214, 0.68871925, 0.12941176, 0.58924831,\n",
      "       0.29107981]),\n",
      "  0.4606584746150136),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62575956, 0.43973214, 0.68871925, 0.12941176, 0.58924831,\n",
      "       0.29107981]),\n",
      "  0.4606584746150136),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62575956, 0.43973214, 0.68871925, 0.12941176, 0.58924831,\n",
      "       0.29107981]),\n",
      "  0.4606584746150136),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63271605, 0.44172494, 0.65388711, 0.21662469, 0.58081864,\n",
      "       0.22921914]),\n",
      "  0.4591650962225722),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63271605, 0.44172494, 0.65388711, 0.21662469, 0.58081864,\n",
      "       0.22921914]),\n",
      "  0.4591650962225722),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63271605, 0.44172494, 0.65388711, 0.21662469, 0.58081864,\n",
      "       0.22921914]),\n",
      "  0.4591650962225722),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63271605, 0.44172494, 0.65388711, 0.21662469, 0.58081864,\n",
      "       0.22921914]),\n",
      "  0.4591650962225722),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63169041, 0.4374269 , 0.65339614, 0.21994885, 0.57948948,\n",
      "       0.22981956]),\n",
      "  0.4586285568836346),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63169041, 0.4374269 , 0.65339614, 0.21994885, 0.57948948,\n",
      "       0.22981956]),\n",
      "  0.4586285568836346),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63169041, 0.4374269 , 0.65339614, 0.21994885, 0.57948948,\n",
      "       0.22981956]),\n",
      "  0.4586285568836346),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.63169041, 0.4374269 , 0.65339614, 0.21994885, 0.57948948,\n",
      "       0.22981956]),\n",
      "  0.4586285568836346),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62680167, 0.43612335, 0.68695467, 0.12790698, 0.58993476,\n",
      "       0.27987421]),\n",
      "  0.4579326066354669),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62680167, 0.43612335, 0.68695467, 0.12790698, 0.58993476,\n",
      "       0.27987421]),\n",
      "  0.4579326066354669),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62680167, 0.43612335, 0.68695467, 0.12790698, 0.58993476,\n",
      "       0.27987421]),\n",
      "  0.4579326066354669),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62680167, 0.43612335, 0.68695467, 0.12790698, 0.58993476,\n",
      "       0.27987421]),\n",
      "  0.4579326066354669),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64326966, 0.432     , 0.68796592, 0.12048193, 0.59569597,\n",
      "       0.2562396 ]),\n",
      "  0.45594217969915646),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64326966, 0.432     , 0.68796592, 0.12048193, 0.59569597,\n",
      "       0.2562396 ]),\n",
      "  0.45594217969915646),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64326966, 0.432     , 0.68796592, 0.12048193, 0.59569597,\n",
      "       0.2562396 ]),\n",
      "  0.45594217969915646),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64326966, 0.432     , 0.68796592, 0.12048193, 0.59569597,\n",
      "       0.2562396 ]),\n",
      "  0.45594217969915646),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64377778, 0.42694064, 0.68650964, 0.12048193, 0.59758046,\n",
      "       0.26      ]),\n",
      "  0.4558817403023794),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64377778, 0.42694064, 0.68650964, 0.12048193, 0.59758046,\n",
      "       0.26      ]),\n",
      "  0.4558817403023794),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64377778, 0.42694064, 0.68650964, 0.12048193, 0.59758046,\n",
      "       0.26      ]),\n",
      "  0.4558817403023794),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64377778, 0.42694064, 0.68650964, 0.12048193, 0.59758046,\n",
      "       0.26      ]),\n",
      "  0.4558817403023794),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64921666, 0.42059621, 0.64690107, 0.20122699, 0.58053252,\n",
      "       0.20925553]),\n",
      "  0.4512881640967983),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64921666, 0.42059621, 0.64690107, 0.20122699, 0.58053252,\n",
      "       0.20925553]),\n",
      "  0.4512881640967983),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64921666, 0.42059621, 0.64690107, 0.20122699, 0.58053252,\n",
      "       0.20925553]),\n",
      "  0.4512881640967983),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64921666, 0.42059621, 0.64690107, 0.20122699, 0.58053252,\n",
      "       0.20925553]),\n",
      "  0.4512881640967983),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64952199, 0.41935484, 0.64831895, 0.19583843, 0.58072993,\n",
      "       0.2125576 ]),\n",
      "  0.451053623986087),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64952199, 0.41935484, 0.64831895, 0.19583843, 0.58072993,\n",
      "       0.2125576 ]),\n",
      "  0.451053623986087),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64952199, 0.41935484, 0.64831895, 0.19583843, 0.58072993,\n",
      "       0.2125576 ]),\n",
      "  0.451053623986087),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.64952199, 0.41935484, 0.64831895, 0.19583843, 0.58072993,\n",
      "       0.2125576 ]),\n",
      "  0.451053623986087),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72059707, 0.33810688, 0.75115491, 0.26785714, 0.37590361,\n",
      "       0.25138291]),\n",
      "  0.45083375498562656),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72050754, 0.33834324, 0.75192367, 0.26888604, 0.37247208,\n",
      "       0.25231339]),\n",
      "  0.45074099334193857),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72021258, 0.33916084, 0.75180797, 0.26923077, 0.37001209,\n",
      "       0.25278121]),\n",
      "  0.45053424428254973),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71986971, 0.33892383, 0.75196305, 0.26957638, 0.36853253,\n",
      "       0.25208526]),\n",
      "  0.4501584592353207),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71943185, 0.34055944, 0.7533867 , 0.25089606, 0.37736985,\n",
      "       0.25425791]),\n",
      "  0.44931696647217717),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71949341, 0.34067856, 0.75303893, 0.25089606, 0.3768814 ,\n",
      "       0.2541806 ]),\n",
      "  0.4491948258375092),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71963017, 0.34067856, 0.75265507, 0.25059666, 0.3768814 ,\n",
      "       0.25425791]),\n",
      "  0.44911662702681215),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71968531, 0.34091705, 0.75381062, 0.2491018 , 0.3768814 ,\n",
      "       0.25379478]),\n",
      "  0.4490318249425447),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74086987, 0.30883301, 0.74181264, 0.30371567, 0.31869511,\n",
      "       0.23571008]),\n",
      "  0.4416060626403264),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74048262, 0.30818827, 0.74069555, 0.2984127 , 0.32395247,\n",
      "       0.23605783]),\n",
      "  0.44129823916884536),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73981191, 0.30828765, 0.74109047, 0.30441899, 0.31489629,\n",
      "       0.23532881]),\n",
      "  0.44063901931314026),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.74052783, 0.30843529, 0.74173396, 0.3029316 , 0.31350331,\n",
      "       0.23629935]),\n",
      "  0.44057188852472856),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73142158, 0.31377719, 0.73054623, 0.33158813, 0.28763613,\n",
      "       0.23929009]),\n",
      "  0.4390432248889889),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.73068162, 0.31391905, 0.72921434, 0.32933105, 0.2913738 ,\n",
      "       0.23831347]),\n",
      "  0.43880555561479323),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72968955, 0.31092161, 0.72868928, 0.32820513, 0.29064197,\n",
      "       0.23719512]),\n",
      "  0.43755710945745396),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.37174096, 0.61213361, 0.16596815, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.43687905764858453),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.37174096, 0.61213361, 0.16596815, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.43687905764858453),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.37174096, 0.61213361, 0.16596815, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.43687905764858453),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.37174096, 0.61213361, 0.16596815, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.43687905764858453),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72647932, 0.31131458, 0.72619229, 0.32820513, 0.29227824,\n",
      "       0.23653962]),\n",
      "  0.43683486372852554),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7258586 , 0.31239724, 0.72591463, 0.321489  , 0.29570747,\n",
      "       0.23614896]),\n",
      "  0.43625265079587644),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72870524, 0.31287129, 0.72741194, 0.32413793, 0.28736   ,\n",
      "       0.23644717]),\n",
      "  0.43615559562688033),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72657275, 0.31229454, 0.72466422, 0.32478632, 0.29000319,\n",
      "       0.23575998]),\n",
      "  0.43568016925598063),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.36780651, 0.61225604, 0.16751269, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43564373961364056),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.36780651, 0.61225604, 0.16751269, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43564373961364056),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.36780651, 0.61225604, 0.16751269, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43564373961364056),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.36780651, 0.61225604, 0.16751269, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43564373961364056),\n",
      " ({'analyzer': 'word',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.72252771, 0.31096563, 0.72325511, 0.31509121, 0.30155211,\n",
      "       0.23472766]),\n",
      "  0.4346865700595959),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.42059621, 0.61213361, 0.09615385, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.4333858819485454),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.42059621, 0.61213361, 0.09615385, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.4333858819485454),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.42059621, 0.61213361, 0.09615385, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.4333858819485454),\n",
      " ({'analyzer': 'char_wb',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5907697 , 0.42059621, 0.61213361, 0.09615385, 0.55804425,\n",
      "       0.32261768]),\n",
      "  0.4333858819485454),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.42162162, 0.61225604, 0.09631728, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43274702399670145),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.42162162, 0.61225604, 0.09631728, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43274702399670145),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.42162162, 0.61225604, 0.09631728, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43274702399670145),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.5903799 , 0.42162162, 0.61225604, 0.09631728, 0.55558583,\n",
      "       0.32032147]),\n",
      "  0.43274702399670145),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.34369007, 0.6085095 , 0.14918415, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.42764162693314695),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.34369007, 0.6085095 , 0.14918415, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.42764162693314695),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.34369007, 0.6085095 , 0.14918415, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.42764162693314695),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.34369007, 0.6085095 , 0.14918415, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.42764162693314695),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.40019763, 0.6085095 , 0.08850199, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.4269458617643658),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.40019763, 0.6085095 , 0.08850199, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.4269458617643658),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.40019763, 0.6085095 , 0.08850199, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.4269458617643658),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.6077842 , 0.40019763, 0.6085095 , 0.08850199, 0.55461507,\n",
      "       0.30206677]),\n",
      "  0.4269458617643658),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.34655372, 0.60468833, 0.14556482, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42643730095658555),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.34655372, 0.60468833, 0.14556482, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42643730095658555),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.34655372, 0.60468833, 0.14556482, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42643730095658555),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.34655372, 0.60468833, 0.14556482, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42643730095658555),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.39703704, 0.60468833, 0.08825675, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42529984200265786),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.39703704, 0.60468833, 0.08825675, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42529984200265786),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.39703704, 0.60468833, 0.08825675, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42529984200265786),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60863542, 0.39703704, 0.60468833, 0.08825675, 0.55501879,\n",
      "       0.29816273]),\n",
      "  0.42529984200265786),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71684041, 0.31310523, 0.7195861 , 0.23448276, 0.33570765,\n",
      "       0.22508039]),\n",
      "  0.4241337563726961),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71644565, 0.31473069, 0.72196712, 0.22497188, 0.33961099,\n",
      "       0.22502685]),\n",
      "  0.4237921964154077),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.7169301 , 0.31493506, 0.72226337, 0.22446689, 0.33848054,\n",
      "       0.22442953]),\n",
      "  0.4235842495163285),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71670047, 0.31503735, 0.72267416, 0.22222222, 0.33909821,\n",
      "       0.22466488]),\n",
      "  0.4233995490097368),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71593885, 0.31473069, 0.72124352, 0.22573363, 0.33868974,\n",
      "       0.22389262]),\n",
      "  0.4233715093396933),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71730459, 0.31270148, 0.71976314, 0.23515716, 0.33001865,\n",
      "       0.22514071]),\n",
      "  0.42334762170753876),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71683068, 0.31209781, 0.71992898, 0.23488372, 0.33095312,\n",
      "       0.2248996 ]),\n",
      "  0.42326565173517877),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 3),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.71674438, 0.31270148, 0.71952663, 0.23121387, 0.3310559 ,\n",
      "       0.2261617 ]),\n",
      "  0.42290066072593874),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60523748, 0.3076412 , 0.62956127, 0.18833163, 0.29768328,\n",
      "       0.20258398]),\n",
      "  0.3718398033384473),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60523748, 0.3076412 , 0.62956127, 0.18833163, 0.29768328,\n",
      "       0.20258398]),\n",
      "  0.3718398033384473),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60523748, 0.3076412 , 0.62956127, 0.18833163, 0.29768328,\n",
      "       0.20258398]),\n",
      "  0.3718398033384473),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60523748, 0.3076412 , 0.62956127, 0.18833163, 0.29768328,\n",
      "       0.20258398]),\n",
      "  0.3718398033384473),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60473055, 0.30728477, 0.62834377, 0.18828452, 0.2993974 ,\n",
      "       0.20041216]),\n",
      "  0.37140886105554105),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60473055, 0.30728477, 0.62834377, 0.18828452, 0.2993974 ,\n",
      "       0.20041216]),\n",
      "  0.37140886105554105),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60473055, 0.30728477, 0.62834377, 0.18828452, 0.2993974 ,\n",
      "       0.20041216]),\n",
      "  0.37140886105554105),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.60473055, 0.30728477, 0.62834377, 0.18828452, 0.2993974 ,\n",
      "       0.20041216]),\n",
      "  0.37140886105554105),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62204853, 0.29569557, 0.6225    , 0.17322835, 0.27725957,\n",
      "       0.18705378]),\n",
      "  0.36296429941095837),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62204853, 0.29569557, 0.6225    , 0.17322835, 0.27725957,\n",
      "       0.18705378]),\n",
      "  0.36296429941095837),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62204853, 0.29569557, 0.6225    , 0.17322835, 0.27725957,\n",
      "       0.18705378]),\n",
      "  0.36296429941095837),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62204853, 0.29569557, 0.6225    , 0.17322835, 0.27725957,\n",
      "       0.18705378]),\n",
      "  0.36296429941095837),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62246897, 0.29474343, 0.62246316, 0.17764471, 0.27290323,\n",
      "       0.18699187]),\n",
      "  0.36286922897743706),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62246897, 0.29474343, 0.62246316, 0.17764471, 0.27290323,\n",
      "       0.18699187]),\n",
      "  0.36286922897743706),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62246897, 0.29474343, 0.62246316, 0.17764471, 0.27290323,\n",
      "       0.18699187]),\n",
      "  0.36286922897743706),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 2),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.62246897, 0.29474343, 0.62246316, 0.17764471, 0.27290323,\n",
      "       0.18699187]),\n",
      "  0.36286922897743706),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.48012803, 0.33254438, 0.45525998, 0.08      , 0.4266752 ,\n",
      "       0.15021318]),\n",
      "  0.32080346153558936),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.48012803, 0.33254438, 0.45525998, 0.08      , 0.4266752 ,\n",
      "       0.15021318]),\n",
      "  0.32080346153558936),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.48012803, 0.33254438, 0.45525998, 0.08      , 0.4266752 ,\n",
      "       0.15021318]),\n",
      "  0.32080346153558936),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.48012803, 0.33254438, 0.45525998, 0.08      , 0.4266752 ,\n",
      "       0.15021318]),\n",
      "  0.32080346153558936),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.4797877 , 0.33769322, 0.45533835, 0.06432749, 0.42804781,\n",
      "       0.15037594]),\n",
      "  0.3192617511281982),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.4797877 , 0.33769322, 0.45533835, 0.06432749, 0.42804781,\n",
      "       0.15037594]),\n",
      "  0.3192617511281982),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.4797877 , 0.33769322, 0.45533835, 0.06432749, 0.42804781,\n",
      "       0.15037594]),\n",
      "  0.3192617511281982),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.4797877 , 0.33769322, 0.45533835, 0.06432749, 0.42804781,\n",
      "       0.15037594]),\n",
      "  0.3192617511281982),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44608704, 0.34901159, 0.44373605, 0.08805031, 0.41263877,\n",
      "       0.16029144]),\n",
      "  0.3166358670704766),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44608704, 0.34901159, 0.44373605, 0.08805031, 0.41263877,\n",
      "       0.16029144]),\n",
      "  0.3166358670704766),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44608704, 0.34901159, 0.44373605, 0.08805031, 0.41263877,\n",
      "       0.16029144]),\n",
      "  0.3166358670704766),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44608704, 0.34901159, 0.44373605, 0.08805031, 0.41263877,\n",
      "       0.16029144]),\n",
      "  0.3166358670704766),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47922803, 0.32613391, 0.44227598, 0.08628659, 0.41524959,\n",
      "       0.13650964]),\n",
      "  0.3142806231598584),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47922803, 0.32613391, 0.44227598, 0.08628659, 0.41524959,\n",
      "       0.13650964]),\n",
      "  0.3142806231598584),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47922803, 0.32613391, 0.44227598, 0.08628659, 0.41524959,\n",
      "       0.13650964]),\n",
      "  0.3142806231598584),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47922803, 0.32613391, 0.44227598, 0.08628659, 0.41524959,\n",
      "       0.13650964]),\n",
      "  0.3142806231598584),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44564007, 0.34394042, 0.4442665 , 0.07878788, 0.41058237,\n",
      "       0.16105417]),\n",
      "  0.3140452359224844),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44564007, 0.34394042, 0.4442665 , 0.07878788, 0.41058237,\n",
      "       0.16105417]),\n",
      "  0.3140452359224844),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44564007, 0.34394042, 0.4442665 , 0.07878788, 0.41058237,\n",
      "       0.16105417]),\n",
      "  0.3140452359224844),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.44564007, 0.34394042, 0.4442665 , 0.07878788, 0.41058237,\n",
      "       0.16105417]),\n",
      "  0.3140452359224844),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47875817, 0.32219828, 0.44373966, 0.08523592, 0.41549876,\n",
      "       0.13575628]),\n",
      "  0.31353117802251923),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47875817, 0.32219828, 0.44373966, 0.08523592, 0.41549876,\n",
      "       0.13575628]),\n",
      "  0.31353117802251923),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47875817, 0.32219828, 0.44373966, 0.08523592, 0.41549876,\n",
      "       0.13575628]),\n",
      "  0.31353117802251923),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47875817, 0.32219828, 0.44373966, 0.08523592, 0.41549876,\n",
      "       0.13575628]),\n",
      "  0.31353117802251923),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43606593, 0.33292383, 0.43233895, 0.0972973 , 0.39838918,\n",
      "       0.14110787]),\n",
      "  0.3063538445281518),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43606593, 0.33292383, 0.43233895, 0.0972973 , 0.39838918,\n",
      "       0.14110787]),\n",
      "  0.3063538445281518),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43606593, 0.33292383, 0.43233895, 0.0972973 , 0.39838918,\n",
      "       0.14110787]),\n",
      "  0.3063538445281518),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43606593, 0.33292383, 0.43233895, 0.0972973 , 0.39838918,\n",
      "       0.14110787]),\n",
      "  0.3063538445281518),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43637546, 0.32944069, 0.43319838, 0.0910683 , 0.39884643,\n",
      "       0.14159812]),\n",
      "  0.30508789697271155),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43637546, 0.32944069, 0.43319838, 0.0910683 , 0.39884643,\n",
      "       0.14159812]),\n",
      "  0.30508789697271155),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43637546, 0.32944069, 0.43319838, 0.0910683 , 0.39884643,\n",
      "       0.14159812]),\n",
      "  0.30508789697271155),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.25 , 0.06 , 0.13 , 0.03 , 0.12 , 0.025]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43637546, 0.32944069, 0.43319838, 0.0910683 , 0.39884643,\n",
      "       0.14159812]),\n",
      "  0.30508789697271155),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.3146283 , 0.40693535, 0.05445026, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.29974080766001704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.3146283 , 0.40693535, 0.05445026, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.29974080766001704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.3146283 , 0.40693535, 0.05445026, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.29974080766001704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.3146283 , 0.40693535, 0.05445026, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.29974080766001704),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.30969609, 0.40791897, 0.05414787, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.29880359113250504),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.30969609, 0.40791897, 0.05414787, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.29880359113250504),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.30969609, 0.40791897, 0.05414787, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.29880359113250504),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.30969609, 0.40791897, 0.05414787, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.29880359113250504),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.25144804, 0.40693535, 0.07992895, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.2934572132910627),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.25144804, 0.40693535, 0.07992895, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.2934572132910627),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.25144804, 0.40693535, 0.07992895, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.2934572132910627),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45775618, 0.25144804, 0.40693535, 0.07992895, 0.39018552,\n",
      "       0.17448923]),\n",
      "  0.2934572132910627),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.24871178, 0.40791897, 0.07349081, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.2918633642319781),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.24871178, 0.40791897, 0.07349081, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.2918633642319781),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.24871178, 0.40791897, 0.07349081, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.2918633642319781),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.45790853, 0.24871178, 0.40791897, 0.07349081, 0.39058371,\n",
      "       0.17256637]),\n",
      "  0.2918633642319781),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.31171662, 0.39084466, 0.05729565, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.29088798298905105),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.31171662, 0.39084466, 0.05729565, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.29088798298905105),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.31171662, 0.39084466, 0.05729565, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.29088798298905105),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.31171662, 0.39084466, 0.05729565, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.29088798298905105),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.31079607, 0.39326631, 0.05755948, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.290779807063448),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.31079607, 0.39326631, 0.05755948, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.290779807063448),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.31079607, 0.39326631, 0.05755948, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.290779807063448),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.05, 0.1 , 0.01, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.31079607, 0.39326631, 0.05755948, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.290779807063448),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.25453253, 0.39084466, 0.09583333, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.2877802486723254),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.25453253, 0.39084466, 0.09583333, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.2877802486723254),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.25453253, 0.39084466, 0.09583333, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.2877802486723254),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42394376, 0.25453253, 0.39084466, 0.09583333, 0.36875612,\n",
      "       0.19277108]),\n",
      "  0.2877802486723254),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.25293073, 0.39326631, 0.09365245, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.28715107728490114),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.25293073, 0.39326631, 0.09365245, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.28715107728490114),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.25293073, 0.39326631, 0.09365245, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.28715107728490114),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.15, 0.03, 0.1 , 0.02, 0.1 , 0.05]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.42514752, 0.25293073, 0.39326631, 0.09365245, 0.36864772,\n",
      "       0.18926174]),\n",
      "  0.28715107728490114),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43148688, 0.3134715 , 0.41538462, 0.        , 0.36174192,\n",
      "       0.05859375]),\n",
      "  0.2634464444481927),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43148688, 0.3134715 , 0.41538462, 0.        , 0.36174192,\n",
      "       0.05859375]),\n",
      "  0.2634464444481927),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43148688, 0.3134715 , 0.41538462, 0.        , 0.36174192,\n",
      "       0.05859375]),\n",
      "  0.2634464444481927),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43148688, 0.3134715 , 0.41538462, 0.        , 0.36174192,\n",
      "       0.05859375]),\n",
      "  0.2634464444481927),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.39199889, 0.33124216, 0.41986234, 0.        , 0.34792123,\n",
      "       0.0750469 ]),\n",
      "  0.2610119194569744),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.39199889, 0.33124216, 0.41986234, 0.        , 0.34792123,\n",
      "       0.0750469 ]),\n",
      "  0.2610119194569744),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.39199889, 0.33124216, 0.41986234, 0.        , 0.34792123,\n",
      "       0.0750469 ]),\n",
      "  0.2610119194569744),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.39199889, 0.33124216, 0.41986234, 0.        , 0.34792123,\n",
      "       0.0750469 ]),\n",
      "  0.2610119194569744),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43355756, 0.3046875 , 0.41500994, 0.        , 0.36012862,\n",
      "       0.0511811 ]),\n",
      "  0.26076078635819094),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43355756, 0.3046875 , 0.41500994, 0.        , 0.36012862,\n",
      "       0.0511811 ]),\n",
      "  0.26076078635819094),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43355756, 0.3046875 , 0.41500994, 0.        , 0.36012862,\n",
      "       0.0511811 ]),\n",
      "  0.26076078635819094),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43355756, 0.3046875 , 0.41500994, 0.        , 0.36012862,\n",
      "       0.0511811 ]),\n",
      "  0.26076078635819094),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.38903576, 0.32405063, 0.41879921, 0.        , 0.34920635,\n",
      "       0.07561437]),\n",
      "  0.25945105340919467),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.38903576, 0.32405063, 0.41879921, 0.        , 0.34920635,\n",
      "       0.07561437]),\n",
      "  0.25945105340919467),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.38903576, 0.32405063, 0.41879921, 0.        , 0.34920635,\n",
      "       0.07561437]),\n",
      "  0.25945105340919467),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.38903576, 0.32405063, 0.41879921, 0.        , 0.34920635,\n",
      "       0.07561437]),\n",
      "  0.25945105340919467),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37360847, 0.28344371, 0.37729982, 0.        , 0.31151758,\n",
      "       0.05447471]),\n",
      "  0.2333907138652704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37360847, 0.28344371, 0.37729982, 0.        , 0.31151758,\n",
      "       0.05447471]),\n",
      "  0.2333907138652704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37360847, 0.28344371, 0.37729982, 0.        , 0.31151758,\n",
      "       0.05447471]),\n",
      "  0.2333907138652704),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37360847, 0.28344371, 0.37729982, 0.        , 0.31151758,\n",
      "       0.05447471]),\n",
      "  0.2333907138652704),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37423563, 0.28229028, 0.37590862, 0.        , 0.30769231,\n",
      "       0.05426357]),\n",
      "  0.23239840032520476),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37423563, 0.28229028, 0.37590862, 0.        , 0.30769231,\n",
      "       0.05426357]),\n",
      "  0.23239840032520476),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37423563, 0.28229028, 0.37590862, 0.        , 0.30769231,\n",
      "       0.05426357]),\n",
      "  0.23239840032520476),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.37, 0.32, 0.41, 0.35, 0.39, 0.32]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.37423563, 0.28229028, 0.37590862, 0.        , 0.30769231,\n",
      "       0.05426357]),\n",
      "  0.23239840032520476),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32331945, 0.28756477, 0.38129496, 0.        , 0.30317137,\n",
      "       0.07156309]),\n",
      "  0.22781894041137749),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32331945, 0.28756477, 0.38129496, 0.        , 0.30317137,\n",
      "       0.07156309]),\n",
      "  0.22781894041137749),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32331945, 0.28756477, 0.38129496, 0.        , 0.30317137,\n",
      "       0.07156309]),\n",
      "  0.22781894041137749),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32331945, 0.28756477, 0.38129496, 0.        , 0.30317137,\n",
      "       0.07156309]),\n",
      "  0.22781894041137749),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47238095, 0.19990104, 0.42372672, 0.08274232, 0.06411658,\n",
      "       0.11673315]),\n",
      "  0.22660012643605185),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47238095, 0.19990104, 0.42372672, 0.08274232, 0.06411658,\n",
      "       0.11673315]),\n",
      "  0.22660012643605185),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47238095, 0.19990104, 0.42372672, 0.08274232, 0.06411658,\n",
      "       0.11673315]),\n",
      "  0.22660012643605185),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.47238095, 0.19990104, 0.42372672, 0.08274232, 0.06411658,\n",
      "       0.11673315]),\n",
      "  0.22660012643605185),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32350313, 0.28350515, 0.38053553, 0.        , 0.29822002,\n",
      "       0.07089552]),\n",
      "  0.22610989211816365),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32350313, 0.28350515, 0.38053553, 0.        , 0.29822002,\n",
      "       0.07089552]),\n",
      "  0.22610989211816365),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32350313, 0.28350515, 0.38053553, 0.        , 0.29822002,\n",
      "       0.07089552]),\n",
      "  0.22610989211816365),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.45, 0.3 , 0.4 , 0.27, 0.41, 0.27]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.32350313, 0.28350515, 0.38053553, 0.        , 0.29822002,\n",
      "       0.07089552]),\n",
      "  0.22610989211816365),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.46927991, 0.20192545, 0.42212411, 0.08363202, 0.06131387,\n",
      "       0.11617217]),\n",
      "  0.22574125493193484),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.46927991, 0.20192545, 0.42212411, 0.08363202, 0.06131387,\n",
      "       0.11617217]),\n",
      "  0.22574125493193484),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.46927991, 0.20192545, 0.42212411, 0.08363202, 0.06131387,\n",
      "       0.11617217]),\n",
      "  0.22574125493193484),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': False,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.46927991, 0.20192545, 0.42212411, 0.08363202, 0.06131387,\n",
      "       0.11617217]),\n",
      "  0.22574125493193484),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43573338, 0.18756027, 0.40700774, 0.09405256, 0.06756266,\n",
      "       0.11790298]),\n",
      "  0.2183032647513715),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43573338, 0.18756027, 0.40700774, 0.09405256, 0.06756266,\n",
      "       0.11790298]),\n",
      "  0.2183032647513715),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43573338, 0.18756027, 0.40700774, 0.09405256, 0.06756266,\n",
      "       0.11790298]),\n",
      "  0.2183032647513715),\n",
      " ({'analyzer': 'char',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43573338, 0.18756027, 0.40700774, 0.09405256, 0.06756266,\n",
      "       0.11790298]),\n",
      "  0.2183032647513715),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 25000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43396836, 0.18570411, 0.4071826 , 0.09537167, 0.06545455,\n",
      "       0.11815252]),\n",
      "  0.21763896721449605),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 30000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43396836, 0.18570411, 0.4071826 , 0.09537167, 0.06545455,\n",
      "       0.11815252]),\n",
      "  0.21763896721449605),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 35000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43396836, 0.18570411, 0.4071826 , 0.09537167, 0.06545455,\n",
      "       0.11815252]),\n",
      "  0.21763896721449605),\n",
      " ({'analyzer': 'char_wb',\n",
      "   'lowercase': True,\n",
      "   'max_features': 40000,\n",
      "   'ngram_range': (1, 1),\n",
      "   'p_for_classify': array([0.17 , 0.02 , 0.11 , 0.025, 0.9  , 0.02 ]),\n",
      "   'stop_words': {'english'}},\n",
      "  array([0.43396836, 0.18570411, 0.4071826 , 0.09537167, 0.06545455,\n",
      "       0.11815252]),\n",
      "  0.21763896721449605)]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(bgs_results, key = lambda x: x[2], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшими параметрами оказались:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 40000,\n",
       " 'analyzer': 'word',\n",
       " 'lowercase': True,\n",
       " 'ngram_range': (1, 2),\n",
       " 'stop_words': {'english'},\n",
       " 'p_for_classify': array([0.2 , 0.07, 0.15, 0.05, 0.15, 0.03])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bgs_results, key = lambda x: x[2], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что при реализации поиска наилучшего набора параметра была допущена ошибка, существенно влияющаяся на количество вычислений. Дело в том, что набор вероятностей не относится к `TfidfVectorizer`, таким образом при их переборе большое количество раз обучались одни и те же модели лишь с той целью, чтобы оубчиться на другом нбаоре вероятностей. Исправим данную ошибку и реализуем конструктивный подбор вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedMPS(params):\n",
    "    params_list = []\n",
    "    for i in params['max_features']:\n",
    "        for j in params['analyzer']:\n",
    "            for k in params['lowercase']:\n",
    "                for z in params['ngram_range']:\n",
    "                    for l in params['stop_words']:\n",
    "                        params_dict = {'max_features': i,\n",
    "                                        'analyzer': j,\n",
    "                                        'lowercase': k,\n",
    "                                        'ngram_range': z,\n",
    "                                        'stop_words': l}\n",
    "                        params_list.append(params_dict)\n",
    "    return params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_features': [25000, 30000, 35000, 40000],\n",
    "    'analyzer': ['word', 'char', 'char_wb'],\n",
    "    'lowercase': [True, False],\n",
    "    'stop_words': [{'english'}],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'p_for_classify': [p1, p2, p3, p4, p5, p6, p7]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число вариаций гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params = improvedMPS(params)\n",
    "len(all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество моделей, которые необходимо обучить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_params) * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это в семь раз меньше, чем в предыдущей реализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с подбором вероятностей. Будем для каждого набора параметров с помощью `f1_score` подбирать вероятности следующим образом. Начиная с $0.49$ будем с шагом $0.01$ уменьшать вероятности до тех пор, пока точность по `f1_score` увеличивается (так плохо работает, поэтому буду просто перебирать все до $0.01$). Такой способ перебора вероятностей будет гораздо эффективней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedGridSearch(params, X_train, X_test, Y_train, Y_test):\n",
    "    c_all = len(params)  # Общее число гиперпараметров\n",
    "    c = 0  # Счетчик для вывода номера итерации\n",
    "    tested_params = []\n",
    "    for par in params:\n",
    "        c += 1\n",
    "        print('-------| {}/{} |-------'.format(c, c_all))\n",
    "        print('Набор гиперпараметров:')\n",
    "        pprint(par)\n",
    "        # Данные\n",
    "        print('Преобразование данных в векторы:')\n",
    "        count_vec = TfidfVectorizer(max_features=par['max_features'],\n",
    "                                    analyzer=par['analyzer'],\n",
    "                                    lowercase=par['lowercase'],\n",
    "                                    ngram_range=par['ngram_range'],\n",
    "                                    stop_words=par['stop_words'],\n",
    "                                    sublinear_tf=True, \n",
    "                                    strip_accents='unicode', \n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "        comments_vec_train = count_vec.fit_transform(X_train)\n",
    "        print('* X_train преобразован')\n",
    "        comments_vec_test = count_vec.transform(X_test)\n",
    "        print('* X_test преобразован')\n",
    "        # Обучение моделей и подбор вероятностей\n",
    "        print('Обучение моделей и подбор вероятностей:')\n",
    "        models = fit_models(comments_vec_train, Y_train, max_iter=300)\n",
    "        # подбор вероятностей\n",
    "        probs0 = np.zeros(6) + 0.5\n",
    "        best_probs = np.zeros(6) + 0.5\n",
    "        predict = predict_models(comments_vec_test, models, p=probs0)       \n",
    "        for j, ycol in enumerate(Y_test.columns):\n",
    "            f10 = f1_score(Y_test[ycol], predict[:, j])\n",
    "            while probs0[j] > 0.1:\n",
    "                probs0[j] -= 0.01\n",
    "                predict = predict_models(comments_vec_test, models, p=probs0)\n",
    "                f11 = f1_score(Y_test[ycol], predict[:, j])\n",
    "                if f11 > f10:\n",
    "                    best_probs[j] = probs0[j]\n",
    "                    f10 = f11\n",
    "        predict = predict_models(comments_vec_test, models, p=best_probs)\n",
    "        multy_f1 = multy_f1_score(Y_test, predict)\n",
    "        F1 = F1_score(multy_f1)\n",
    "        # Добавление результатов в список\n",
    "        tested_params.append((par, best_probs, multy_f1, F1))\n",
    "        print('Вероятности подобраны')\n",
    "        print('Проверка гиперпараметров завершена.')\n",
    "    # Возвращается список кортежей из:\n",
    "    # набора параметров;\n",
    "    # набора вероятностей\n",
    "    # f1 по всем признакам;\n",
    "    # F1 по f1.\n",
    "    return tested_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'analyzer': 'word',\n",
      "  'lowercase': True,\n",
      "  'max_features': 25000,\n",
      "  'ngram_range': (1, 1),\n",
      "  'stop_words': {'english'}}]\n"
     ]
    }
   ],
   "source": [
    "test_params = [all_params[0]]\n",
    "pprint(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------| 1/1 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'max_features': 25000,\n",
       "   'analyzer': 'word',\n",
       "   'lowercase': True,\n",
       "   'ngram_range': (1, 1),\n",
       "   'stop_words': {'english'}},\n",
       "  array([0.28, 0.1 , 0.18, 0.13, 0.23, 0.12]),\n",
       "  array([0.78144477, 0.49337261, 0.80587507, 0.46387833, 0.72124233,\n",
       "         0.44654088]),\n",
       "  0.6187256642669435)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improvedGridSearch(test_params, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим в пакетном GridSearch старую функцию простого GridSearch на новую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedBatchedGridSearch(all_params, X_train, X_test, Y_train, Y_test, k):\n",
    "    # Количество наборов гиперпараметров должно быть кратно k\n",
    "    all_results = []\n",
    "    total_time = 0\n",
    "    for i in range(0, len(all_params), k):  # пакеты гиперпараметров\n",
    "        params_batch = all_params[i:i+k]\n",
    "        print('\\n=====| Обработка пакета номер {}/{} |====='.format(int(i/k+1),\n",
    "                                                                  int(len(all_params)/k)))\n",
    "        s0 = time_now()  # расчет времени\n",
    "        try:\n",
    "            gs_res = improvedGridSearch(params_batch,\n",
    "                                        X_train, X_test,\n",
    "                                        Y_train, Y_test)\n",
    "            for res_j in gs_res:\n",
    "                all_results.append(res_j)\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('\\nОбработка пакета {} завершена за {} секунд'.format(int(i/k+1), ds))\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\n!!! Выполнение было прервано пользователем')\n",
    "            break\n",
    "            # return -1\n",
    "        except:\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('!!! В пакете номер {} произошла ошибка. Пакет:'.format(int(i/k+1)))\n",
    "            pprint(params_batch)\n",
    "    h, m = int(total_time / 3600), int(total_time / 60) % 60\n",
    "    s = total_time - (h*3600 + m*60)\n",
    "    time_str = '\\nОбщее время выполнения: {} секунд или {}ч:{}м:{}с'.format(\n",
    "        total_time, h, m, s\n",
    "    )\n",
    "    print(time_str)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим перебор гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====| Обработка пакета номер 1/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 1 завершена за 513 секунд\n",
      "\n",
      "=====| Обработка пакета номер 2/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 2 завершена за 955 секунд\n",
      "\n",
      "=====| Обработка пакета номер 3/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 3 завершена за 1206 секунд\n",
      "\n",
      "=====| Обработка пакета номер 4/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 4 завершена за 552 секунд\n",
      "\n",
      "=====| Обработка пакета номер 5/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 5 завершена за 961 секунд\n",
      "\n",
      "=====| Обработка пакета номер 6/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 6 завершена за 1210 секунд\n",
      "\n",
      "=====| Обработка пакета номер 7/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 7 завершена за 538 секунд\n",
      "\n",
      "=====| Обработка пакета номер 8/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 8 завершена за 948 секунд\n",
      "\n",
      "=====| Обработка пакета номер 9/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 9 завершена за 1187 секунд\n",
      "\n",
      "=====| Обработка пакета номер 10/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 10 завершена за 550 секунд\n",
      "\n",
      "=====| Обработка пакета номер 11/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 11 завершена за 965 секунд\n",
      "\n",
      "=====| Обработка пакета номер 12/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n",
      "* Модель на  toxic  обучена\n",
      "* Модель на  severe_toxic  обучена\n",
      "* Модель на  obscene  обучена\n",
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n",
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 12 завершена за 1200 секунд\n",
      "\n",
      "Общее время выполнения: 10785 секунд или 2ч:59м:45с\n"
     ]
    }
   ],
   "source": [
    "improvedBGSres = improvedBatchedGridSearch(all_params,\n",
    "                                           X_train, X_test,\n",
    "                                           y_train, y_test, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший набор гиперпараметров для `TfidfVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'analyzer': 'word',\n",
      "  'lowercase': True,\n",
      "  'max_features': 25000,\n",
      "  'ngram_range': (1, 1),\n",
      "  'stop_words': {'english'}},\n",
      " array([0.28, 0.1 , 0.18, 0.13, 0.23, 0.12]),\n",
      " array([0.78144477, 0.49337261, 0.80587507, 0.46387833, 0.72124233,\n",
      "       0.44654088]),\n",
      " 0.6187256642669435)\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(improvedBGSres, key = lambda x: x[-1], reverse=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно создадим такой же подбор параметров для `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedGridSearchCV(params, X_train, X_test, Y_train, Y_test):\n",
    "    c_all = len(params)  # Общее число гиперпараметров\n",
    "    c = 0  # Счетчик для вывода номера итерации\n",
    "    tested_params = []\n",
    "    for par in params:\n",
    "        c += 1\n",
    "        print('-------| {}/{} |-------'.format(c, c_all))\n",
    "        print('Набор гиперпараметров:')\n",
    "        pprint(par)\n",
    "        # Данные\n",
    "        print('Преобразование данных в векторы:')\n",
    "        count_vec = CountVectorizer(max_features=par['max_features'],\n",
    "                                          analyzer=par['analyzer'],\n",
    "                                          lowercase=par['lowercase'],\n",
    "                                          ngram_range=par['ngram_range'],\n",
    "                                          stop_words=par['stop_words'],\n",
    "                                          strip_accents='unicode',\n",
    "                                          token_pattern=r'\\w{1,}')\n",
    "        comments_vec_train = count_vec.fit_transform(X_train)\n",
    "        print('* X_train преобразован')\n",
    "        comments_vec_test = count_vec.transform(X_test)\n",
    "        print('* X_test преобразован')\n",
    "        # Обучение моделей и подбор вероятностей\n",
    "        print('Обучение моделей и подбор вероятностей:')\n",
    "        models = fit_models(comments_vec_train, Y_train, max_iter=300)\n",
    "        # подбор вероятностей\n",
    "        probs0 = np.zeros(6) + 0.5\n",
    "        best_probs = np.zeros(6) + 0.5\n",
    "        predict = predict_models(comments_vec_test, models, p=probs0)       \n",
    "        for j, ycol in enumerate(Y_test.columns):\n",
    "            f10 = f1_score(Y_test[ycol], predict[:, j])\n",
    "            while probs0[j] > 0.1:\n",
    "                probs0[j] -= 0.01\n",
    "                predict = predict_models(comments_vec_test, models, p=probs0)\n",
    "                f11 = f1_score(Y_test[ycol], predict[:, j])\n",
    "                if f11 > f10:\n",
    "                    best_probs[j] = probs0[j]\n",
    "                    f10 = f11\n",
    "        predict = predict_models(comments_vec_test, models, p=best_probs)\n",
    "        multy_f1 = multy_f1_score(Y_test, predict)\n",
    "        F1 = F1_score(multy_f1)\n",
    "        # Добавление результатов в список\n",
    "        tested_params.append((par, best_probs, multy_f1, F1))\n",
    "        print('Вероятности подобраны')\n",
    "        print('Проверка гиперпараметров завершена.')\n",
    "    # Возвращается список кортежей из:\n",
    "    # набора параметров;\n",
    "    # набора вероятностей\n",
    "    # f1 по всем признакам;\n",
    "    # F1 по f1.\n",
    "    return tested_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'analyzer': 'word',\n",
      "  'lowercase': True,\n",
      "  'max_features': 25000,\n",
      "  'ngram_range': (1, 1),\n",
      "  'stop_words': {'english'}}]\n"
     ]
    }
   ],
   "source": [
    "test_params = [all_params[0]]\n",
    "pprint(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будет много больших сообщений о несходимости, но качество 0.56\n",
    "# improvedGridSearchCV(test_params, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedBatchedGridSearchCV(all_params, X_train, X_test, Y_train, Y_test, k):\n",
    "    # Количество наборов гиперпараметров должно быть кратно k\n",
    "    all_results = []\n",
    "    total_time = 0\n",
    "    for i in range(0, len(all_params), k):  # пакеты гиперпараметров\n",
    "        params_batch = all_params[i:i+k]\n",
    "        print('\\n=====| Обработка пакета номер {}/{} |====='.format(int(i/k+1),\n",
    "                                                                  int(len(all_params)/k)))\n",
    "        s0 = time_now()  # расчет времени\n",
    "        try:\n",
    "            gs_res = improvedGridSearchCV(params_batch,\n",
    "                                          X_train, X_test,\n",
    "                                          Y_train, Y_test)\n",
    "            for res_j in gs_res:\n",
    "                all_results.append(res_j)\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('\\nОбработка пакета {} завершена за {} секунд'.format(int(i/k+1), ds))\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\n!!! Выполнение было прервано пользователем')\n",
    "            break\n",
    "            # return -1\n",
    "        except:\n",
    "            s1 = time_now()  # расчет времени\n",
    "            ds = s1 - s0  # расчет времени\n",
    "            total_time += ds  # расчет времени\n",
    "            print('!!! В пакете номер {} произошла ошибка. Пакет:'.format(int(i/k+1)))\n",
    "            pprint(params_batch)\n",
    "    h, m = int(total_time / 3600), int(total_time / 60) % 60\n",
    "    s = total_time - (h*3600 + m*60)\n",
    "    time_str = '\\nОбщее время выполнения: {} секунд или {}ч:{}м:{}с'.format(\n",
    "        total_time, h, m, s\n",
    "    )\n",
    "    print(time_str)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====| Обработка пакета номер 1/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 1 завершена за 961 секунд\n",
      "\n",
      "=====| Обработка пакета номер 2/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 2 завершена за 1932 секунд\n",
      "\n",
      "=====| Обработка пакета номер 3/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 25000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 3 завершена за 2058 секунд\n",
      "\n",
      "=====| Обработка пакета номер 4/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 4 завершена за 1004 секунд\n",
      "\n",
      "=====| Обработка пакета номер 5/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 5 завершена за 1965 секунд\n",
      "\n",
      "=====| Обработка пакета номер 6/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 30000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 6 завершена за 2073 секунд\n",
      "\n",
      "=====| Обработка пакета номер 7/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 7 завершена за 1074 секунд\n",
      "\n",
      "=====| Обработка пакета номер 8/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 8 завершена за 2387 секунд\n",
      "\n",
      "=====| Обработка пакета номер 9/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 35000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 9 завершена за 2559 секунд\n",
      "\n",
      "=====| Обработка пакета номер 10/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'word',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 10 завершена за 2096 секунд\n",
      "\n",
      "=====| Обработка пакета номер 11/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n",
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 11 завершена за 2299 секунд\n",
      "\n",
      "=====| Обработка пакета номер 12/12 |=====\n",
      "-------| 1/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 2/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 3/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': True,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 4/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 1),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 5/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 2),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "-------| 6/6 |-------\n",
      "Набор гиперпараметров:\n",
      "{'analyzer': 'char_wb',\n",
      " 'lowercase': False,\n",
      " 'max_features': 40000,\n",
      " 'ngram_range': (1, 3),\n",
      " 'stop_words': {'english'}}\n",
      "Преобразование данных в векторы:\n",
      "* X_train преобразован\n",
      "* X_test преобразован\n",
      "Обучение моделей и подбор вероятностей:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  severe_toxic  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  obscene  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  threat  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  insult  обучена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ski6a\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Модель на  identity_hate  обучена\n",
      "Обучение всех моделей завершено\n",
      "Вероятности подобраны\n",
      "Проверка гиперпараметров завершена.\n",
      "\n",
      "Обработка пакета 12 завершена за 3226 секунд\n",
      "\n",
      "Общее время выполнения: 23634 секунд или 6ч:33м:54с\n"
     ]
    }
   ],
   "source": [
    "improvedBGSCVres = improvedBatchedGridSearchCV(all_params,\n",
    "                                             X_train, X_test,\n",
    "                                             y_train, y_test, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший набор гиперпараметров для `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'analyzer': 'word',\n",
      "  'lowercase': True,\n",
      "  'max_features': 40000,\n",
      "  'ngram_range': (1, 2),\n",
      "  'stop_words': {'english'}},\n",
      " array([0.32, 0.14, 0.22, 0.1 , 0.23, 0.15]),\n",
      " array([0.7671013 , 0.46034483, 0.78428571, 0.42816901, 0.69735112,\n",
      "       0.43636364]),\n",
      " 0.5956026023370865)\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(improvedBGSCVres, key = lambda x: x[-1], reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
